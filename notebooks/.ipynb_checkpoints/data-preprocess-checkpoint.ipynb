{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2e3aa0d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.2-cp38-cp38-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /Users/astonuser/anaconda3/envs/transformer_time_series_forecast/lib/python3.8/site-packages (from scikit-learn) (1.24.4)\n",
      "Collecting scipy>=1.5.0 (from scikit-learn)\n",
      "  Downloading scipy-1.10.1-cp38-cp38-macosx_12_0_arm64.whl (28.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.8/28.8 MB\u001b[0m \u001b[31m524.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.1.1 (from scikit-learn)\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Downloading scikit_learn-1.3.2-cp38-cp38-macosx_12_0_arm64.whl (9.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m657.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m330.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.3.2 scipy-1.10.1 threadpoolctl-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1368,
   "id": "7205202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, Tensor, IntTensor\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ef1f5d",
   "metadata": {},
   "source": [
    "# WALMART"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bfe65d",
   "metadata": {},
   "source": [
    "### TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df45dee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>IsHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>46039.49</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-19</td>\n",
       "      <td>41595.55</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>19403.54</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-03-05</td>\n",
       "      <td>21827.90</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421565</th>\n",
       "      <td>45</td>\n",
       "      <td>98</td>\n",
       "      <td>2012-09-28</td>\n",
       "      <td>508.37</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421566</th>\n",
       "      <td>45</td>\n",
       "      <td>98</td>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>628.10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421567</th>\n",
       "      <td>45</td>\n",
       "      <td>98</td>\n",
       "      <td>2012-10-12</td>\n",
       "      <td>1061.02</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421568</th>\n",
       "      <td>45</td>\n",
       "      <td>98</td>\n",
       "      <td>2012-10-19</td>\n",
       "      <td>760.01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421569</th>\n",
       "      <td>45</td>\n",
       "      <td>98</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>1076.80</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>421570 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Store  Dept        Date  Weekly_Sales  IsHoliday\n",
       "0           1     1  2010-02-05      24924.50      False\n",
       "1           1     1  2010-02-12      46039.49       True\n",
       "2           1     1  2010-02-19      41595.55      False\n",
       "3           1     1  2010-02-26      19403.54      False\n",
       "4           1     1  2010-03-05      21827.90      False\n",
       "...       ...   ...         ...           ...        ...\n",
       "421565     45    98  2012-09-28        508.37      False\n",
       "421566     45    98  2012-10-05        628.10      False\n",
       "421567     45    98  2012-10-12       1061.02      False\n",
       "421568     45    98  2012-10-19        760.01      False\n",
       "421569     45    98  2012-10-26       1076.80      False\n",
       "\n",
       "[421570 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walmart_sales_train_df = pd.read_csv(\"../data/raw/train.csv\")\n",
    "walmart_sales_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "13415de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество тренировочных строк - 421570\n",
      "Количество колонок - 5\n",
      "\n",
      "Колонки:\n",
      "\n",
      "Store\n",
      "Dept\n",
      "Date\n",
      "Weekly_Sales\n",
      "IsHoliday\n"
     ]
    }
   ],
   "source": [
    "print(f\"Количество тренировочных строк - {walmart_sales_train_df.shape[0]}\")\n",
    "print(f\"Количество колонок - {walmart_sales_train_df.shape[1]}\")\n",
    "print(f\"\\nКолонки:\\n\")\n",
    "print('\\n'.join(walmart_sales_train_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "275487b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Store - номер магазина \n",
      "\n",
      "Dept - номер департамента магазина\n",
      "\n",
      "Date - дата\n",
      "\n",
      "Weekly_Sales - продажи за неделю(таргет)\n",
      "\n",
      "IsHoliday - выходной ли\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "Store - номер магазина \\n\n",
    "Dept - номер департамента магазина\\n\n",
    "Date - дата\\n\n",
    "Weekly_Sales - продажи за неделю(таргет)\\n\n",
    "IsHoliday - выходной ли\\n\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d24f27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>421570.000000</td>\n",
       "      <td>421570.000000</td>\n",
       "      <td>421570.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.200546</td>\n",
       "      <td>44.260317</td>\n",
       "      <td>15981.258123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.785297</td>\n",
       "      <td>30.492054</td>\n",
       "      <td>22711.183519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4988.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2079.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>7612.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>20205.852500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>693099.360000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Store           Dept   Weekly_Sales\n",
       "count  421570.000000  421570.000000  421570.000000\n",
       "mean       22.200546      44.260317   15981.258123\n",
       "std        12.785297      30.492054   22711.183519\n",
       "min         1.000000       1.000000   -4988.940000\n",
       "25%        11.000000      18.000000    2079.650000\n",
       "50%        22.000000      37.000000    7612.030000\n",
       "75%        33.000000      74.000000   20205.852500\n",
       "max        45.000000      99.000000  693099.360000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walmart_sales_train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5cc7b0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Магазины могут быть - [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45]\n",
      "Длина - 45\n",
      "\n",
      "Департаменты могут быть - [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58, 59, 60, 65, 67, 71, 72, 74, 77, 78, 79, 80, 81, 82, 83, 85, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "Длина - 81\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Сount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3326</th>\n",
       "      <td>45</td>\n",
       "      <td>94</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3327</th>\n",
       "      <td>45</td>\n",
       "      <td>95</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3328</th>\n",
       "      <td>45</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3329</th>\n",
       "      <td>45</td>\n",
       "      <td>97</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3330</th>\n",
       "      <td>45</td>\n",
       "      <td>98</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3331 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Store  Dept  Сount\n",
       "0         1     1    143\n",
       "1         1     2    143\n",
       "2         1     3    143\n",
       "3         1     4    143\n",
       "4         1     5    143\n",
       "...     ...   ...    ...\n",
       "3326     45    94    134\n",
       "3327     45    95    143\n",
       "3328     45    96      2\n",
       "3329     45    97    143\n",
       "3330     45    98    135\n",
       "\n",
       "[3331 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_store = walmart_sales_train_df.Store.unique()\n",
    "print(f\"Магазины могут быть - {unique_store}\")\n",
    "print(f\"Длина - {len(unique_store)}\\n\")\n",
    "\n",
    "unique_dept = sorted(list(walmart_sales_train_df.Dept.unique()))\n",
    "print(f\"Департаменты могут быть - {unique_dept}\")\n",
    "print(f\"Длина - {len(unique_dept)}\\n\")\n",
    "\n",
    "walmart_sales_train_df.groupby(['Store','Dept']).size().reset_index().rename(columns={0:'Сount'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762460f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3336621e",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12394f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Date</th>\n",
       "      <th>IsHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-11-02</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-11-09</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-11-16</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-11-23</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-11-30</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115059</th>\n",
       "      <td>45</td>\n",
       "      <td>98</td>\n",
       "      <td>2013-06-28</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115060</th>\n",
       "      <td>45</td>\n",
       "      <td>98</td>\n",
       "      <td>2013-07-05</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115061</th>\n",
       "      <td>45</td>\n",
       "      <td>98</td>\n",
       "      <td>2013-07-12</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115062</th>\n",
       "      <td>45</td>\n",
       "      <td>98</td>\n",
       "      <td>2013-07-19</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115063</th>\n",
       "      <td>45</td>\n",
       "      <td>98</td>\n",
       "      <td>2013-07-26</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115064 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Store  Dept        Date  IsHoliday\n",
       "0           1     1  2012-11-02      False\n",
       "1           1     1  2012-11-09      False\n",
       "2           1     1  2012-11-16      False\n",
       "3           1     1  2012-11-23       True\n",
       "4           1     1  2012-11-30      False\n",
       "...       ...   ...         ...        ...\n",
       "115059     45    98  2013-06-28      False\n",
       "115060     45    98  2013-07-05      False\n",
       "115061     45    98  2013-07-12      False\n",
       "115062     45    98  2013-07-19      False\n",
       "115063     45    98  2013-07-26      False\n",
       "\n",
       "[115064 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walmart_sales_test_df = pd.read_csv(\"../data/raw/test.csv\")\n",
    "walmart_sales_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b82bd78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2013-07-26 00:00:00')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_dates = walmart_sales_test_df[(walmart_sales_test_df.Store == 1) & (walmart_sales_test_df.Dept == 1)].Date\n",
    "\n",
    "temp_dates = pd.to_datetime(temp_dates)\n",
    "temp_dates.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a1203a",
   "metadata": {},
   "source": [
    "### FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3cbcc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Date</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>IsHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>38.51</td>\n",
       "      <td>2.548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.242170</td>\n",
       "      <td>8.106</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-19</td>\n",
       "      <td>39.93</td>\n",
       "      <td>2.514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.289143</td>\n",
       "      <td>8.106</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>46.63</td>\n",
       "      <td>2.561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.319643</td>\n",
       "      <td>8.106</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-03-05</td>\n",
       "      <td>46.50</td>\n",
       "      <td>2.625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.350143</td>\n",
       "      <td>8.106</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8185</th>\n",
       "      <td>45</td>\n",
       "      <td>2013-06-28</td>\n",
       "      <td>76.05</td>\n",
       "      <td>3.639</td>\n",
       "      <td>4842.29</td>\n",
       "      <td>975.03</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2449.97</td>\n",
       "      <td>3169.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8186</th>\n",
       "      <td>45</td>\n",
       "      <td>2013-07-05</td>\n",
       "      <td>77.50</td>\n",
       "      <td>3.614</td>\n",
       "      <td>9090.48</td>\n",
       "      <td>2268.58</td>\n",
       "      <td>582.74</td>\n",
       "      <td>5797.47</td>\n",
       "      <td>1514.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8187</th>\n",
       "      <td>45</td>\n",
       "      <td>2013-07-12</td>\n",
       "      <td>79.37</td>\n",
       "      <td>3.614</td>\n",
       "      <td>3789.94</td>\n",
       "      <td>1827.31</td>\n",
       "      <td>85.72</td>\n",
       "      <td>744.84</td>\n",
       "      <td>2150.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8188</th>\n",
       "      <td>45</td>\n",
       "      <td>2013-07-19</td>\n",
       "      <td>82.84</td>\n",
       "      <td>3.737</td>\n",
       "      <td>2961.49</td>\n",
       "      <td>1047.07</td>\n",
       "      <td>204.19</td>\n",
       "      <td>363.00</td>\n",
       "      <td>1059.46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8189</th>\n",
       "      <td>45</td>\n",
       "      <td>2013-07-26</td>\n",
       "      <td>76.06</td>\n",
       "      <td>3.804</td>\n",
       "      <td>212.02</td>\n",
       "      <td>851.73</td>\n",
       "      <td>2.06</td>\n",
       "      <td>10.88</td>\n",
       "      <td>1864.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8190 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Store        Date  Temperature  Fuel_Price  MarkDown1  MarkDown2  \\\n",
       "0         1  2010-02-05        42.31       2.572        NaN        NaN   \n",
       "1         1  2010-02-12        38.51       2.548        NaN        NaN   \n",
       "2         1  2010-02-19        39.93       2.514        NaN        NaN   \n",
       "3         1  2010-02-26        46.63       2.561        NaN        NaN   \n",
       "4         1  2010-03-05        46.50       2.625        NaN        NaN   \n",
       "...     ...         ...          ...         ...        ...        ...   \n",
       "8185     45  2013-06-28        76.05       3.639    4842.29     975.03   \n",
       "8186     45  2013-07-05        77.50       3.614    9090.48    2268.58   \n",
       "8187     45  2013-07-12        79.37       3.614    3789.94    1827.31   \n",
       "8188     45  2013-07-19        82.84       3.737    2961.49    1047.07   \n",
       "8189     45  2013-07-26        76.06       3.804     212.02     851.73   \n",
       "\n",
       "      MarkDown3  MarkDown4  MarkDown5         CPI  Unemployment  IsHoliday  \n",
       "0           NaN        NaN        NaN  211.096358         8.106      False  \n",
       "1           NaN        NaN        NaN  211.242170         8.106       True  \n",
       "2           NaN        NaN        NaN  211.289143         8.106      False  \n",
       "3           NaN        NaN        NaN  211.319643         8.106      False  \n",
       "4           NaN        NaN        NaN  211.350143         8.106      False  \n",
       "...         ...        ...        ...         ...           ...        ...  \n",
       "8185       3.00    2449.97    3169.69         NaN           NaN      False  \n",
       "8186     582.74    5797.47    1514.93         NaN           NaN      False  \n",
       "8187      85.72     744.84    2150.36         NaN           NaN      False  \n",
       "8188     204.19     363.00    1059.46         NaN           NaN      False  \n",
       "8189       2.06      10.88    1864.57         NaN           NaN      False  \n",
       "\n",
       "[8190 rows x 12 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walmart_features_df = pd.read_csv(\"../data/raw/features.csv\")\n",
    "walmart_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "716df0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "walmart_features_df.Date = pd.to_datetime(walmart_features_df.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9b7efa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2010-02-05    45\n",
      "2012-04-13    45\n",
      "2012-04-27    45\n",
      "2012-05-04    45\n",
      "2012-05-11    45\n",
      "2012-05-18    45\n",
      "2012-05-25    45\n",
      "2012-06-01    45\n",
      "2012-06-08    45\n",
      "2012-06-15    45\n",
      "2012-06-22    45\n",
      "2012-06-29    45\n",
      "2012-07-06    45\n",
      "2012-07-13    45\n",
      "2012-07-20    45\n",
      "2012-07-27    45\n",
      "2012-08-03    45\n",
      "2012-08-10    45\n",
      "2012-08-17    45\n",
      "2012-08-24    45\n",
      "2012-08-31    45\n",
      "2012-04-20    45\n",
      "2012-04-06    45\n",
      "2012-09-14    45\n",
      "2012-03-30    45\n",
      "2011-11-18    45\n",
      "2011-11-25    45\n",
      "2011-12-02    45\n",
      "2011-12-09    45\n",
      "2011-12-16    45\n",
      "2011-12-23    45\n",
      "2011-12-30    45\n",
      "2012-01-06    45\n",
      "2012-01-13    45\n",
      "2012-01-20    45\n",
      "2012-01-27    45\n",
      "2012-02-03    45\n",
      "2012-02-10    45\n",
      "2012-02-17    45\n",
      "2012-02-24    45\n",
      "2012-03-02    45\n",
      "2012-03-09    45\n",
      "2012-03-16    45\n",
      "2012-03-23    45\n",
      "2012-09-07    45\n",
      "2012-09-21    45\n",
      "2010-02-12    45\n",
      "2013-03-01    45\n",
      "2013-03-15    45\n",
      "2013-03-22    45\n",
      "2013-03-29    45\n",
      "2013-04-05    45\n",
      "2013-04-12    45\n",
      "2013-04-19    45\n",
      "2013-04-26    45\n",
      "2013-05-03    45\n",
      "2013-05-10    45\n",
      "2013-05-17    45\n",
      "2013-05-24    45\n",
      "2013-05-31    45\n",
      "2013-06-07    45\n",
      "2013-06-14    45\n",
      "2013-06-21    45\n",
      "2013-06-28    45\n",
      "2013-07-05    45\n",
      "2013-07-12    45\n",
      "2013-07-19    45\n",
      "2013-03-08    45\n",
      "2013-02-22    45\n",
      "2012-09-28    45\n",
      "2013-02-15    45\n",
      "2012-10-05    45\n",
      "2012-10-12    45\n",
      "2012-10-19    45\n",
      "2012-10-26    45\n",
      "2012-11-02    45\n",
      "2012-11-09    45\n",
      "2012-11-16    45\n",
      "2012-11-23    45\n",
      "2012-11-30    45\n",
      "2012-12-07    45\n",
      "2012-12-14    45\n",
      "2012-12-21    45\n",
      "2012-12-28    45\n",
      "2013-01-04    45\n",
      "2013-01-11    45\n",
      "2013-01-18    45\n",
      "2013-01-25    45\n",
      "2013-02-01    45\n",
      "2013-02-08    45\n",
      "2011-11-11    45\n",
      "2011-11-04    45\n",
      "2011-10-28    45\n",
      "2010-07-16    45\n",
      "2010-07-30    45\n",
      "2010-08-06    45\n",
      "2010-08-13    45\n",
      "2010-08-20    45\n",
      "2010-08-27    45\n",
      "2010-09-03    45\n",
      "2010-09-10    45\n",
      "2010-09-17    45\n",
      "2010-09-24    45\n",
      "2010-10-01    45\n",
      "2010-10-08    45\n",
      "2010-10-15    45\n",
      "2010-10-22    45\n",
      "2010-10-29    45\n",
      "2010-11-05    45\n",
      "2010-11-12    45\n",
      "2010-11-19    45\n",
      "2010-11-26    45\n",
      "2010-12-03    45\n",
      "2010-07-23    45\n",
      "2010-07-09    45\n",
      "2011-10-21    45\n",
      "2010-07-02    45\n",
      "2010-02-19    45\n",
      "2010-02-26    45\n",
      "2010-03-05    45\n",
      "2010-03-12    45\n",
      "2010-03-19    45\n",
      "2010-03-26    45\n",
      "2010-04-02    45\n",
      "2010-04-09    45\n",
      "2010-04-16    45\n",
      "2010-04-23    45\n",
      "2010-04-30    45\n",
      "2010-05-07    45\n",
      "2010-05-14    45\n",
      "2010-05-21    45\n",
      "2010-05-28    45\n",
      "2010-06-04    45\n",
      "2010-06-11    45\n",
      "2010-06-18    45\n",
      "2010-06-25    45\n",
      "2010-12-10    45\n",
      "2010-12-17    45\n",
      "2010-12-24    45\n",
      "2010-12-31    45\n",
      "2011-06-10    45\n",
      "2011-06-17    45\n",
      "2011-06-24    45\n",
      "2011-07-01    45\n",
      "2011-07-08    45\n",
      "2011-07-15    45\n",
      "2011-07-22    45\n",
      "2011-07-29    45\n",
      "2011-08-05    45\n",
      "2011-08-12    45\n",
      "2011-08-19    45\n",
      "2011-08-26    45\n",
      "2011-09-02    45\n",
      "2011-09-09    45\n",
      "2011-09-16    45\n",
      "2011-09-23    45\n",
      "2011-09-30    45\n",
      "2011-10-07    45\n",
      "2011-10-14    45\n",
      "2011-06-03    45\n",
      "2011-05-27    45\n",
      "2011-05-20    45\n",
      "2011-03-04    45\n",
      "2011-01-07    45\n",
      "2011-01-14    45\n",
      "2011-01-21    45\n",
      "2011-01-28    45\n",
      "2011-02-04    45\n",
      "2011-02-11    45\n",
      "2011-02-18    45\n",
      "2011-02-25    45\n",
      "2011-03-11    45\n",
      "2011-05-13    45\n",
      "2011-03-18    45\n",
      "2011-03-25    45\n",
      "2011-04-01    45\n",
      "2011-04-08    45\n",
      "2011-04-15    45\n",
      "2011-04-22    45\n",
      "2011-04-29    45\n",
      "2011-05-06    45\n",
      "2013-07-26    45\n"
     ]
    }
   ],
   "source": [
    "print(walmart_features_df.Date.value_counts().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd3420b",
   "metadata": {},
   "source": [
    "### Stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d91682f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>202307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "      <td>37392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>205863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B</td>\n",
       "      <td>34875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>A</td>\n",
       "      <td>202505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>B</td>\n",
       "      <td>70713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>A</td>\n",
       "      <td>155078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>B</td>\n",
       "      <td>125833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>B</td>\n",
       "      <td>126512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>A</td>\n",
       "      <td>207499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>B</td>\n",
       "      <td>112238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>A</td>\n",
       "      <td>219622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>A</td>\n",
       "      <td>200898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>B</td>\n",
       "      <td>123737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>B</td>\n",
       "      <td>57197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>B</td>\n",
       "      <td>93188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>B</td>\n",
       "      <td>120653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>A</td>\n",
       "      <td>203819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>A</td>\n",
       "      <td>203742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>B</td>\n",
       "      <td>140167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>B</td>\n",
       "      <td>119557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>B</td>\n",
       "      <td>114533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>A</td>\n",
       "      <td>203819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>B</td>\n",
       "      <td>128107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>A</td>\n",
       "      <td>152513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>A</td>\n",
       "      <td>204184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>A</td>\n",
       "      <td>206302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>B</td>\n",
       "      <td>93638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>C</td>\n",
       "      <td>42988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>A</td>\n",
       "      <td>203750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>A</td>\n",
       "      <td>203007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>A</td>\n",
       "      <td>39690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>A</td>\n",
       "      <td>158114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>B</td>\n",
       "      <td>103681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>A</td>\n",
       "      <td>39910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>C</td>\n",
       "      <td>39910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>C</td>\n",
       "      <td>39690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>A</td>\n",
       "      <td>184109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>A</td>\n",
       "      <td>155083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>A</td>\n",
       "      <td>196321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>C</td>\n",
       "      <td>39690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>C</td>\n",
       "      <td>41062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>C</td>\n",
       "      <td>39910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>B</td>\n",
       "      <td>118221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Store Type    Size\n",
       "0       1    A  151315\n",
       "1       2    A  202307\n",
       "2       3    B   37392\n",
       "3       4    A  205863\n",
       "4       5    B   34875\n",
       "5       6    A  202505\n",
       "6       7    B   70713\n",
       "7       8    A  155078\n",
       "8       9    B  125833\n",
       "9      10    B  126512\n",
       "10     11    A  207499\n",
       "11     12    B  112238\n",
       "12     13    A  219622\n",
       "13     14    A  200898\n",
       "14     15    B  123737\n",
       "15     16    B   57197\n",
       "16     17    B   93188\n",
       "17     18    B  120653\n",
       "18     19    A  203819\n",
       "19     20    A  203742\n",
       "20     21    B  140167\n",
       "21     22    B  119557\n",
       "22     23    B  114533\n",
       "23     24    A  203819\n",
       "24     25    B  128107\n",
       "25     26    A  152513\n",
       "26     27    A  204184\n",
       "27     28    A  206302\n",
       "28     29    B   93638\n",
       "29     30    C   42988\n",
       "30     31    A  203750\n",
       "31     32    A  203007\n",
       "32     33    A   39690\n",
       "33     34    A  158114\n",
       "34     35    B  103681\n",
       "35     36    A   39910\n",
       "36     37    C   39910\n",
       "37     38    C   39690\n",
       "38     39    A  184109\n",
       "39     40    A  155083\n",
       "40     41    A  196321\n",
       "41     42    C   39690\n",
       "42     43    C   41062\n",
       "43     44    C   39910\n",
       "44     45    B  118221"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walmart_stores_df = pd.read_csv(\"../data/raw/stores.csv\")\n",
    "walmart_stores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54cf6ed",
   "metadata": {},
   "source": [
    "#### Merging datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "e6d3c88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.merge(walmart_stores_df, pd.merge(walmart_sales_train_df, walmart_features_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "5d61616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=[\"MarkDown1\", 'MarkDown2', 'MarkDown3', \"MarkDown4\", 'MarkDown5', 'Type', 'Fuel_Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "18cb1574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Size</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>151315</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>False</td>\n",
       "      <td>42.31</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>151315</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>50605.27</td>\n",
       "      <td>False</td>\n",
       "      <td>42.31</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>151315</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>13740.12</td>\n",
       "      <td>False</td>\n",
       "      <td>42.31</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>151315</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>39954.04</td>\n",
       "      <td>False</td>\n",
       "      <td>42.31</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>151315</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>32229.38</td>\n",
       "      <td>False</td>\n",
       "      <td>42.31</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421565</th>\n",
       "      <td>45</td>\n",
       "      <td>118221</td>\n",
       "      <td>93</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>2487.80</td>\n",
       "      <td>False</td>\n",
       "      <td>58.85</td>\n",
       "      <td>192.308899</td>\n",
       "      <td>8.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421566</th>\n",
       "      <td>45</td>\n",
       "      <td>118221</td>\n",
       "      <td>94</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>5203.31</td>\n",
       "      <td>False</td>\n",
       "      <td>58.85</td>\n",
       "      <td>192.308899</td>\n",
       "      <td>8.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421567</th>\n",
       "      <td>45</td>\n",
       "      <td>118221</td>\n",
       "      <td>95</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>56017.47</td>\n",
       "      <td>False</td>\n",
       "      <td>58.85</td>\n",
       "      <td>192.308899</td>\n",
       "      <td>8.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421568</th>\n",
       "      <td>45</td>\n",
       "      <td>118221</td>\n",
       "      <td>97</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>6817.48</td>\n",
       "      <td>False</td>\n",
       "      <td>58.85</td>\n",
       "      <td>192.308899</td>\n",
       "      <td>8.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421569</th>\n",
       "      <td>45</td>\n",
       "      <td>118221</td>\n",
       "      <td>98</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>1076.80</td>\n",
       "      <td>False</td>\n",
       "      <td>58.85</td>\n",
       "      <td>192.308899</td>\n",
       "      <td>8.667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>421570 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Store    Size  Dept        Date  Weekly_Sales  IsHoliday  Temperature  \\\n",
       "0           1  151315     1  2010-02-05      24924.50      False        42.31   \n",
       "1           1  151315     2  2010-02-05      50605.27      False        42.31   \n",
       "2           1  151315     3  2010-02-05      13740.12      False        42.31   \n",
       "3           1  151315     4  2010-02-05      39954.04      False        42.31   \n",
       "4           1  151315     5  2010-02-05      32229.38      False        42.31   \n",
       "...       ...     ...   ...         ...           ...        ...          ...   \n",
       "421565     45  118221    93  2012-10-26       2487.80      False        58.85   \n",
       "421566     45  118221    94  2012-10-26       5203.31      False        58.85   \n",
       "421567     45  118221    95  2012-10-26      56017.47      False        58.85   \n",
       "421568     45  118221    97  2012-10-26       6817.48      False        58.85   \n",
       "421569     45  118221    98  2012-10-26       1076.80      False        58.85   \n",
       "\n",
       "               CPI  Unemployment  \n",
       "0       211.096358         8.106  \n",
       "1       211.096358         8.106  \n",
       "2       211.096358         8.106  \n",
       "3       211.096358         8.106  \n",
       "4       211.096358         8.106  \n",
       "...            ...           ...  \n",
       "421565  192.308899         8.667  \n",
       "421566  192.308899         8.667  \n",
       "421567  192.308899         8.667  \n",
       "421568  192.308899         8.667  \n",
       "421569  192.308899         8.667  \n",
       "\n",
       "[421570 rows x 9 columns]"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3269d938",
   "metadata": {},
   "source": [
    "#### Preprocessing Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "19747ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.Date = pd.to_datetime(X.Date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d0d608",
   "metadata": {},
   "source": [
    "#### Sorting X by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "721fff48",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.sort_values(by=['Date', 'Store'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127f11df",
   "metadata": {},
   "source": [
    "#### Replacing date with number of a week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "56843b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Week'] = X.Date.apply(lambda x: x.isocalendar()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "c469ae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(['Date'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95851374",
   "metadata": {},
   "source": [
    "#### Splitting dataset to train/val/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "f1c07953",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_len = X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "905c95a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = 0.1\n",
    "val_ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "63e675ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = int(X_len * test_ratio)\n",
    "val_size = int(X_len * val_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "faacaa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X.iloc[X_len-test_size:]\n",
    "X_val = X.iloc[X_len-test_size-val_size:X_len-test_size]\n",
    "X_train = X.iloc[:X_len-test_size-val_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fb6fa7",
   "metadata": {},
   "source": [
    "#### Preprocessing Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "9983ce5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {color: black;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" checked><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_label_encoder = LabelEncoder()\n",
    "store_label_encoder.fit(sorted(list(X_train.Store.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "535da5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/astonuser/anaconda3/envs/transformer_time_series_forecast/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/var/folders/7x/qzp6r7jn19gf5g0r68gpc_3r0000gp/T/ipykernel_764/3350660351.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['Store'] = store_label_encoder.transform(X_train[['Store']])\n",
      "/Users/astonuser/anaconda3/envs/transformer_time_series_forecast/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/var/folders/7x/qzp6r7jn19gf5g0r68gpc_3r0000gp/T/ipykernel_764/3350660351.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val['Store'] = store_label_encoder.transform(X_val[['Store']])\n",
      "/Users/astonuser/anaconda3/envs/transformer_time_series_forecast/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/var/folders/7x/qzp6r7jn19gf5g0r68gpc_3r0000gp/T/ipykernel_764/3350660351.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Store'] = store_label_encoder.transform(X_test[['Store']])\n"
     ]
    }
   ],
   "source": [
    "X_train['Store'] = store_label_encoder.transform(X_train[['Store']])\n",
    "X_val['Store'] = store_label_encoder.transform(X_val[['Store']])\n",
    "X_test['Store'] = store_label_encoder.transform(X_test[['Store']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cac5b6",
   "metadata": {},
   "source": [
    "#### Preprocessing Dept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "60c121ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-20 {color: black;}#sk-container-id-20 pre{padding: 0;}#sk-container-id-20 div.sk-toggleable {background-color: white;}#sk-container-id-20 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-20 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-20 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-20 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-20 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-20 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-20 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-20 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-20 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-20 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-20 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-20 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-20 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-20 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-20 div.sk-item {position: relative;z-index: 1;}#sk-container-id-20 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-20 div.sk-item::before, #sk-container-id-20 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-20 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-20 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-20 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-20 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-20 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-20 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-20 div.sk-label-container {text-align: center;}#sk-container-id-20 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-20 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-20\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" checked><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dept_label_encoder = LabelEncoder()\n",
    "dept_label_encoder.fit(sorted(list(X_train.Dept.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "62fcee52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/astonuser/anaconda3/envs/transformer_time_series_forecast/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/var/folders/7x/qzp6r7jn19gf5g0r68gpc_3r0000gp/T/ipykernel_764/2324919871.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['Dept'] = dept_label_encoder.transform(X_train[['Dept']])\n",
      "/Users/astonuser/anaconda3/envs/transformer_time_series_forecast/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/var/folders/7x/qzp6r7jn19gf5g0r68gpc_3r0000gp/T/ipykernel_764/2324919871.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val['Dept'] = dept_label_encoder.transform(X_val[['Dept']])\n",
      "/Users/astonuser/anaconda3/envs/transformer_time_series_forecast/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/var/folders/7x/qzp6r7jn19gf5g0r68gpc_3r0000gp/T/ipykernel_764/2324919871.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['Dept'] = dept_label_encoder.transform(X_test[['Dept']])\n"
     ]
    }
   ],
   "source": [
    "X_train['Dept'] = dept_label_encoder.transform(X_train[['Dept']])\n",
    "X_val['Dept'] = dept_label_encoder.transform(X_val[['Dept']])\n",
    "X_test['Dept'] = dept_label_encoder.transform(X_test[['Dept']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab31457d",
   "metadata": {},
   "source": [
    "#### Preprocessing Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "22bde054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-21 {color: black;}#sk-container-id-21 pre{padding: 0;}#sk-container-id-21 div.sk-toggleable {background-color: white;}#sk-container-id-21 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-21 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-21 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-21 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-21 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-21 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-21 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-21 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-21 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-21 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-21 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-21 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-21 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-21 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-21 div.sk-item {position: relative;z-index: 1;}#sk-container-id-21 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-21 div.sk-item::before, #sk-container-id-21 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-21 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-21 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-21 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-21 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-21 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-21 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-21 div.sk-label-container {text-align: center;}#sk-container-id-21 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-21 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-21\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" checked><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_min_max_scaler = MinMaxScaler()\n",
    "size_min_max_scaler.fit(X_train[['Size']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "77b887ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7x/qzp6r7jn19gf5g0r68gpc_3r0000gp/T/ipykernel_764/2702060106.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train.Size = size_min_max_scaler.transform(X_train[['Size']])\n",
      "/var/folders/7x/qzp6r7jn19gf5g0r68gpc_3r0000gp/T/ipykernel_764/2702060106.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val.Size = size_min_max_scaler.transform(X_val[['Size']])\n",
      "/var/folders/7x/qzp6r7jn19gf5g0r68gpc_3r0000gp/T/ipykernel_764/2702060106.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test.Size = size_min_max_scaler.transform(X_test[['Size']])\n"
     ]
    }
   ],
   "source": [
    "X_train.Size = size_min_max_scaler.transform(X_train[['Size']])\n",
    "X_val.Size = size_min_max_scaler.transform(X_val[['Size']])\n",
    "X_test.Size = size_min_max_scaler.transform(X_test[['Size']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d335e7f7",
   "metadata": {},
   "source": [
    "#### Preprocessing IsHoliday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "4288e0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_holiday_transformer = lambda x: 1 if x else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "419f02b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7x/qzp6r7jn19gf5g0r68gpc_3r0000gp/T/ipykernel_764/3890250643.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train.IsHoliday = X_train.IsHoliday.apply(is_holiday_transformer)\n",
      "/var/folders/7x/qzp6r7jn19gf5g0r68gpc_3r0000gp/T/ipykernel_764/3890250643.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val.IsHoliday = X_val.IsHoliday.apply(is_holiday_transformer)\n",
      "/var/folders/7x/qzp6r7jn19gf5g0r68gpc_3r0000gp/T/ipykernel_764/3890250643.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test.IsHoliday = X_test.IsHoliday.apply(is_holiday_transformer)\n"
     ]
    }
   ],
   "source": [
    "X_train.IsHoliday = X_train.IsHoliday.apply(is_holiday_transformer)\n",
    "X_val.IsHoliday = X_val.IsHoliday.apply(is_holiday_transformer)\n",
    "X_test.IsHoliday = X_test.IsHoliday.apply(is_holiday_transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9957f8e",
   "metadata": {},
   "source": [
    "#### Preprocessing Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "2212f2da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-22 {color: black;}#sk-container-id-22 pre{padding: 0;}#sk-container-id-22 div.sk-toggleable {background-color: white;}#sk-container-id-22 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-22 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-22 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-22 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-22 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-22 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-22 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-22 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-22 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-22 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-22 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-22 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-22 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-22 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-22 div.sk-item {position: relative;z-index: 1;}#sk-container-id-22 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-22 div.sk-item::before, #sk-container-id-22 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-22 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-22 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-22 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-22 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-22 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-22 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-22 div.sk-label-container {text-align: center;}#sk-container-id-22 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-22 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-22\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" checked><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_min_max_scaler = MinMaxScaler()\n",
    "temperature_min_max_scaler.fit(X_train[['Temperature']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "e5a6c6d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7x/qzp6r7jn19gf5g0r68gpc_3r0000gp/T/ipykernel_764/1389029567.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train.Temperature = temperature_min_max_scaler.transform(X_train[['Temperature']])\n",
      "/var/folders/7x/qzp6r7jn19gf5g0r68gpc_3r0000gp/T/ipykernel_764/1389029567.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val.Temperature = temperature_min_max_scaler.transform(X_val[['Temperature']])\n",
      "/var/folders/7x/qzp6r7jn19gf5g0r68gpc_3r0000gp/T/ipykernel_764/1389029567.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test.Temperature = temperature_min_max_scaler.transform(X_test[['Temperature']])\n"
     ]
    }
   ],
   "source": [
    "X_train.Temperature = temperature_min_max_scaler.transform(X_train[['Temperature']])\n",
    "X_val.Temperature = temperature_min_max_scaler.transform(X_val[['Temperature']])\n",
    "X_test.Temperature = temperature_min_max_scaler.transform(X_test[['Temperature']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bbbc96",
   "metadata": {},
   "source": [
    "#### Preprocessing CPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "0aafff9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-23 {color: black;}#sk-container-id-23 pre{padding: 0;}#sk-container-id-23 div.sk-toggleable {background-color: white;}#sk-container-id-23 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-23 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-23 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-23 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-23 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-23 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-23 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-23 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-23 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-23 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-23 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-23 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-23 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-23 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-23 div.sk-item {position: relative;z-index: 1;}#sk-container-id-23 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-23 div.sk-item::before, #sk-container-id-23 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-23 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-23 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-23 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-23 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-23 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-23 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-23 div.sk-label-container {text-align: center;}#sk-container-id-23 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-23 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-23\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" checked><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpi_min_max_scaler = MinMaxScaler()\n",
    "cpi_min_max_scaler.fit(X_train[['CPI']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "b22a8d8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7x/qzp6r7jn19gf5g0r68gpc_3r0000gp/T/ipykernel_764/2361466852.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train.CPI = cpi_min_max_scaler.transform(X_train[['CPI']])\n",
      "/var/folders/7x/qzp6r7jn19gf5g0r68gpc_3r0000gp/T/ipykernel_764/2361466852.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val.CPI = cpi_min_max_scaler.transform(X_val[['CPI']])\n",
      "/var/folders/7x/qzp6r7jn19gf5g0r68gpc_3r0000gp/T/ipykernel_764/2361466852.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test.CPI = cpi_min_max_scaler.transform(X_test[['CPI']])\n"
     ]
    }
   ],
   "source": [
    "X_train.CPI = cpi_min_max_scaler.transform(X_train[['CPI']])\n",
    "X_val.CPI = cpi_min_max_scaler.transform(X_val[['CPI']])\n",
    "X_test.CPI = cpi_min_max_scaler.transform(X_test[['CPI']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01745040",
   "metadata": {},
   "source": [
    "#### Preprocessing Unemployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "8bad449c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-24 {color: black;}#sk-container-id-24 pre{padding: 0;}#sk-container-id-24 div.sk-toggleable {background-color: white;}#sk-container-id-24 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-24 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-24 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-24 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-24 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-24 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-24 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-24 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-24 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-24 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-24 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-24 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-24 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-24 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-24 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-24 div.sk-item {position: relative;z-index: 1;}#sk-container-id-24 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-24 div.sk-item::before, #sk-container-id-24 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-24 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-24 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-24 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-24 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-24 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-24 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-24 div.sk-label-container {text-align: center;}#sk-container-id-24 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-24 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-24\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" checked><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unemployment_min_max_scaler = MinMaxScaler()\n",
    "unemployment_min_max_scaler.fit(X_train[['Unemployment']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "75b424cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7x/qzp6r7jn19gf5g0r68gpc_3r0000gp/T/ipykernel_764/1471874588.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train.Unemployment = unemployment_min_max_scaler.transform(X_train[['Unemployment']])\n",
      "/var/folders/7x/qzp6r7jn19gf5g0r68gpc_3r0000gp/T/ipykernel_764/1471874588.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val.Unemployment = unemployment_min_max_scaler.transform(X_val[['Unemployment']])\n",
      "/var/folders/7x/qzp6r7jn19gf5g0r68gpc_3r0000gp/T/ipykernel_764/1471874588.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test.Unemployment = unemployment_min_max_scaler.transform(X_test[['Unemployment']])\n"
     ]
    }
   ],
   "source": [
    "X_train.Unemployment = unemployment_min_max_scaler.transform(X_train[['Unemployment']])\n",
    "X_val.Unemployment = unemployment_min_max_scaler.transform(X_val[['Unemployment']])\n",
    "X_test.Unemployment = unemployment_min_max_scaler.transform(X_test[['Unemployment']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e082f9b6",
   "metadata": {},
   "source": [
    "#### Preprocessing Weekly_Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "b6bf7a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-25 {color: black;}#sk-container-id-25 pre{padding: 0;}#sk-container-id-25 div.sk-toggleable {background-color: white;}#sk-container-id-25 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-25 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-25 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-25 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-25 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-25 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-25 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-25 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-25 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-25 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-25 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-25 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-25 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-25 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-25 div.sk-item {position: relative;z-index: 1;}#sk-container-id-25 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-25 div.sk-item::before, #sk-container-id-25 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-25 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-25 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-25 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-25 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-25 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-25 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-25 div.sk-label-container {text-align: center;}#sk-container-id-25 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-25 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-25\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>QuantileTransformer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" checked><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">QuantileTransformer</label><div class=\"sk-toggleable__content\"><pre>QuantileTransformer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "QuantileTransformer()"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_sales_quantile_transformer = QuantileTransformer()\n",
    "weekly_sales_quantile_transformer.fit(X_train[['Weekly_Sales']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "37df29de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7x/qzp6r7jn19gf5g0r68gpc_3r0000gp/T/ipykernel_764/3902564762.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train.Weekly_Sales = weekly_sales_quantile_transformer.transform(X_train[['Weekly_Sales']])\n",
      "/var/folders/7x/qzp6r7jn19gf5g0r68gpc_3r0000gp/T/ipykernel_764/3902564762.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val.Weekly_Sales = weekly_sales_quantile_transformer.transform(X_val[['Weekly_Sales']])\n",
      "/var/folders/7x/qzp6r7jn19gf5g0r68gpc_3r0000gp/T/ipykernel_764/3902564762.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test.Weekly_Sales = weekly_sales_quantile_transformer.transform(X_test[['Weekly_Sales']])\n"
     ]
    }
   ],
   "source": [
    "X_train.Weekly_Sales = weekly_sales_quantile_transformer.transform(X_train[['Weekly_Sales']])\n",
    "X_val.Weekly_Sales = weekly_sales_quantile_transformer.transform(X_val[['Weekly_Sales']])\n",
    "X_test.Weekly_Sales = weekly_sales_quantile_transformer.transform(X_test[['Weekly_Sales']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2a3a8e",
   "metadata": {},
   "source": [
    "### Making Temporary Store Sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be24b60e",
   "metadata": {},
   "source": [
    "Store[1...45]:\n",
    "    dept\n",
    "    size\n",
    "    date - list\n",
    "    weekly - list\n",
    "    is_holiday - list\n",
    "    temperature - list\n",
    "    CPI - list\n",
    "    Unemployment - list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "id": "b74a382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoreSales:\n",
    "    def __init__(self, store, dept, size, week, weekly_sales, is_holiday, temperature, cpi, unemployment, indices_window_size, indices_step_size):\n",
    "        self.store = store\n",
    "        self.dept = dept\n",
    "        self.size = size\n",
    "        \n",
    "        self.week = week\n",
    "        self.week_sin = self.sin_transform(self.week)\n",
    "        self.week_cos = self.cos_transform(self.week)\n",
    "        \n",
    "        self.weekly_sales = weekly_sales\n",
    "        self.is_holiday = is_holiday\n",
    "        self.temperature = temperature\n",
    "        self.cpi = cpi\n",
    "        self.unemployment = unemployment\n",
    "        \n",
    "        self.indices = self.get_indices(window_size=indices_window_size, step_size=indices_step_size)\n",
    "    \n",
    "    def get_indices(self, window_size, step_size):\n",
    "        \n",
    "        stop_position = len(self.weekly_sales) - 1\n",
    "        \n",
    "        subseq_first_idx = 0\n",
    "        \n",
    "        subseq_last_idx = window_size\n",
    "        \n",
    "        indices = []\n",
    "        \n",
    "        while subseq_last_idx <= stop_position:\n",
    "\n",
    "            indices.append((subseq_first_idx, subseq_last_idx))\n",
    "            \n",
    "            subseq_first_idx += step_size\n",
    "            \n",
    "            subseq_last_idx += step_size\n",
    "\n",
    "        return indices\n",
    "    \n",
    "    def get_sequence(self, index):\n",
    "        tabular_categorical_features = (self.store, self.dept)\n",
    "        tabular_numerical_features = (self.size)\n",
    "        tabular_features = [tabular_categorical_features, tabular_numerical_features]\n",
    "\n",
    "        start_idx = self.indices[index][0]\n",
    "        end_idx = self.indices[index][1]\n",
    "        \n",
    "        weeks = self.week[start_idx:end_idx]\n",
    "        weeks_sin = self.week_sin[start_idx:end_idx]\n",
    "        weeks_cos = self.week_cos[start_idx:end_idx]\n",
    "        \n",
    "        time_series = self.weekly_sales[start_idx:end_idx]\n",
    "        \n",
    "        holidays = self.is_holiday[start_idx:end_idx]\n",
    "        temperatures = self.temperature[start_idx:end_idx]\n",
    "        cpis = self.cpi[start_idx:end_idx]\n",
    "        unemployments = self.unemployment[start_idx:end_idx]\n",
    "        \n",
    "        time_series_features = [((holidays[i]), (time_series[i], weeks_sin[i], weeks_cos[i], temperatures[i], cpis[i], unemployments[i])) for i in range(len(time_series))]\n",
    "        \n",
    "        return (tabular_features, time_series_features)\n",
    "    \n",
    "    def sin_transform(self, values):\n",
    "        values = np.array(values)\n",
    "        return np.sin(2 * np.pi * values / 52)\n",
    "\n",
    "    def cos_transform(self, values):\n",
    "        values = np.array(values)\n",
    "        return np.cos(2 * np.pi * values / 52)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1421,
   "id": "c7de3052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_temp_store_sales(df):\n",
    "    stores_sales = []\n",
    "    store_nums = sorted(list(X_train.Store.unique()))\n",
    "    for store_num in store_nums:\n",
    "        df_store = df[df.Store == store_num]\n",
    "    \n",
    "        dept_nums = sorted(list(df_store.Dept.unique()))\n",
    "    \n",
    "        for dept_num in dept_nums:\n",
    "            df_store_dept = df_store[df_store.Dept == dept_num]\n",
    "        \n",
    "            store_dept_sales = StoreSales(\n",
    "                store=store_num,\n",
    "                dept=dept_num, \n",
    "                size=float(df_store_dept.Size.unique()[0]), \n",
    "                week=df_store_dept.Week.tolist(), \n",
    "                weekly_sales=df_store_dept.Weekly_Sales.tolist(), \n",
    "                is_holiday=df_store_dept.IsHoliday.tolist(), \n",
    "                temperature=df_store_dept.Temperature.tolist(), \n",
    "                cpi=df_store_dept.CPI.tolist(), \n",
    "                unemployment=df_store_dept.Unemployment.tolist(), \n",
    "                indices_window_size=14, \n",
    "                indices_step_size=1)\n",
    "        \n",
    "            stores_sales.append(store_dept_sales)\n",
    "    return stores_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1422,
   "id": "44584d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_store_sales = get_temp_store_sales(X_train)\n",
    "val_store_sales = get_temp_store_sales(X_val)\n",
    "test_store_sales = get_temp_store_sales(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1423,
   "id": "a296301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subsequences(store_sales):\n",
    "    subsequences = []\n",
    "    for store_sale in store_sales:\n",
    "        for subsequence_i in range(len(store_sale.indices)):\n",
    "            subsequent = store_sale.get_sequence(subsequence_i)\n",
    "            subsequences.append(subsequent)\n",
    "    return subsequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1424,
   "id": "24a1aa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = get_subsequences(train_store_sales)\n",
    "val_sequences = get_subsequences(val_store_sales)\n",
    "test_sequences = get_subsequences(test_store_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1425,
   "id": "2ee461ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250840"
      ]
     },
     "execution_count": 1425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1426,
   "id": "971db877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41657"
      ]
     },
     "execution_count": 1426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1427,
   "id": "3a24d49e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "632"
      ]
     },
     "execution_count": 1427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1428,
   "id": "799b3d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 1428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sequences[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507f308a",
   "metadata": {},
   "source": [
    "## Making Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1466,
   "id": "afeec0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WalmartDataset(Dataset):\n",
    "    def __init__(self, data, enc_seq_len: int, dec_seq_len: int, target_seq_len: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.data = data # (tabular_features,time_series_features)\n",
    "        \n",
    "        self.enc_seq_len = enc_seq_len\n",
    "        self.dec_seq_len = dec_seq_len\n",
    "        self.target_seq_len = target_seq_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        item = self.data[index]\n",
    "        \n",
    "        tabular_features, time_series_features = item\n",
    "        src_time_series_categorical_features, src_time_series_numerical_features, trg_time_series_categorical_features, trg_time_series_numerical_features, trg_y = self.get_src_trg(time_series_features)\n",
    "        \n",
    "        tabular_categorical_features, tabular_numerical_features = tabular_features\n",
    "        tabular_categorical_features, tabular_numerical_features = list(tabular_categorical_features), [tabular_numerical_features]\n",
    "        \n",
    "        return {\n",
    "            'tabular_categorical_features': torch.IntTensor(tabular_categorical_features),\n",
    "            'tabular_numerical_features': torch.Tensor(tabular_numerical_features),\n",
    "            'src_time_series_categorical_features': torch.IntTensor(src_time_series_categorical_features),\n",
    "            'src_time_series_numerical_features': torch.Tensor(src_time_series_numerical_features),\n",
    "            'trg_time_series_categorical_features': torch.IntTensor(trg_time_series_categorical_features),\n",
    "            'trg_time_series_numerical_features': torch.Tensor(trg_time_series_numerical_features),\n",
    "            'trg_y': torch.Tensor(trg_y)\n",
    "        }\n",
    "        \n",
    "    \n",
    "    def get_src_trg(\n",
    "            self,\n",
    "            time_series_features\n",
    "    ) -> Tuple[torch.tensor, torch.tensor, torch.tensor]:\n",
    "\n",
    "        #assert len(time_series_features) == self.enc_seq_len + self.target_seq_len, \"Features length does not equal (input length + target length)\"\n",
    "        \n",
    "        time_series_categorical_features = []\n",
    "        time_series_numerical_features = []\n",
    "        for t in range(len(time_series_features)):\n",
    "            time_step = time_series_features[t]\n",
    "            time_series_categorical_features.append(time_step[0])\n",
    "            time_series_numerical_features.append(list(time_step[1]))\n",
    "        \n",
    "        src_time_series_categorical_features = time_series_categorical_features[:self.enc_seq_len]\n",
    "        src_time_series_numerical_features = time_series_numerical_features[:self.enc_seq_len]\n",
    "        \n",
    "        trg_time_series_categorical_features = time_series_categorical_features[self.enc_seq_len - 1:len(time_series_categorical_features) - 1]\n",
    "        trg_time_series_numerical_features = time_series_numerical_features[self.enc_seq_len - 1:len(time_series_numerical_features) - 1]\n",
    "\n",
    "        #assert len(trg_time_series_numerical_features) == self.dec_seq_len, \"Length of trg num does not match target sequence length\"\n",
    "        #assert len(trg_time_series_categorical_features) == self.dec_seq_len, \"Length of trg cat does not match target sequence length\"\n",
    "\n",
    "        \n",
    "        trg_y_numerical_features = trg_time_series_numerical_features[-self.target_seq_len:]\n",
    "        \n",
    "        trg_y = [trg_y_numerical_features[-1][0]]\n",
    "        \n",
    "        return src_time_series_categorical_features, src_time_series_numerical_features, trg_time_series_categorical_features, trg_time_series_numerical_features, trg_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1467,
   "id": "d6f88583",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_seq_len = 10\n",
    "dec_seq_len = 4\n",
    "target_seq_len = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1468,
   "id": "2e4824ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = WalmartDataset(\n",
    "    data=train_sequences, \n",
    "    enc_seq_len=enc_seq_len, \n",
    "    dec_seq_len=dec_seq_len, \n",
    "    target_seq_len=target_seq_len\n",
    ")\n",
    "\n",
    "val_dataset = WalmartDataset(\n",
    "    data=val_sequences, \n",
    "    enc_seq_len=enc_seq_len, \n",
    "    dec_seq_len=dec_seq_len, \n",
    "    target_seq_len=target_seq_len\n",
    ")\n",
    "\n",
    "test_dataset = WalmartDataset(\n",
    "    data=test_sequences, \n",
    "    enc_seq_len=enc_seq_len, \n",
    "    dec_seq_len=dec_seq_len, \n",
    "    target_seq_len=target_seq_len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1469,
   "id": "adb37d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tabular_categorical_features': tensor([0, 0], dtype=torch.int32),\n",
       " 'tabular_numerical_features': tensor([0.6303]),\n",
       " 'src_time_series_categorical_features': tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32),\n",
       " 'src_time_series_numerical_features': tensor([[ 7.9145e-01,  5.6806e-01,  8.2298e-01,  4.3415e-01,  8.7330e-01,\n",
       "           3.7259e-01],\n",
       "         [ 9.1101e-01,  6.6312e-01,  7.4851e-01,  3.9697e-01,  8.7480e-01,\n",
       "           3.7259e-01],\n",
       "         [ 8.9396e-01,  7.4851e-01,  6.6312e-01,  4.1086e-01,  8.7528e-01,\n",
       "           3.7259e-01],\n",
       "         [ 7.3433e-01,  8.2298e-01,  5.6806e-01,  4.7642e-01,  8.7559e-01,\n",
       "           3.7259e-01],\n",
       "         [ 7.6264e-01,  8.8546e-01,  4.6472e-01,  4.7515e-01,  8.7590e-01,\n",
       "           3.7259e-01],\n",
       "         [ 7.5371e-01,  9.3502e-01,  3.5460e-01,  5.8562e-01,  8.7622e-01,\n",
       "           3.7259e-01],\n",
       "         [ 7.6572e-01,  9.7094e-01,  2.3932e-01,  5.5421e-01,  8.7452e-01,\n",
       "           3.7259e-01],\n",
       "         [ 8.0047e-01,  9.9271e-01,  1.2054e-01,  5.2358e-01,  8.7249e-01,\n",
       "           3.7259e-01],\n",
       "         [ 9.4087e-01,  1.0000e+00, -1.6081e-16,  6.2945e-01,  8.7046e-01,\n",
       "           3.4246e-01],\n",
       "         [ 8.9971e-01,  9.9271e-01, -1.2054e-01,  6.6458e-01,  8.6844e-01,\n",
       "           3.4246e-01]]),\n",
       " 'trg_time_series_categorical_features': tensor([0, 0, 0, 0], dtype=torch.int32),\n",
       " 'trg_time_series_numerical_features': tensor([[ 0.8997,  0.9927, -0.1205,  0.6646,  0.8684,  0.3425],\n",
       "         [ 0.7110,  0.9709, -0.2393,  0.6691,  0.8671,  0.3425],\n",
       "         [ 0.6903,  0.9350, -0.3546,  0.6546,  0.8665,  0.3425],\n",
       "         [ 0.6957,  0.8855, -0.4647,  0.6797,  0.8660,  0.3425]]),\n",
       " 'trg_y': tensor([0.6957])}"
      ]
     },
     "execution_count": 1469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1586,
   "id": "91b664c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from torch import nn, Tensor, IntTensor\n",
    "\n",
    "\n",
    "class FeedForwardLayer(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_size=1,\n",
    "            hidden_size=32,\n",
    "            output_size=32\n",
    "    ):\n",
    "        super(FeedForwardLayer, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EmbeddingLayer(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            tabular_cat_features_size: int,  # 2\n",
    "            tabular_cat_features_possible_nums: IntTensor,  # [45, 81]\n",
    "            tabular_cat_features_embeddings_dim: int,  # 32\n",
    "\n",
    "            tabular_num_features_size: int,  # 1\n",
    "            tabular_num_features_ffn_hidden_size: int,  # 32\n",
    "            tabular_num_features_ffn_output_dim: int,  # 22\n",
    "\n",
    "            time_series_cat_features_size: int,  # 1\n",
    "            time_series_cat_features_possible_nums: IntTensor,  # [2]\n",
    "            time_series_cat_features_embeddings_dim: int,  # 16\n",
    "\n",
    "            time_series_size: int,  # 10\n",
    "\n",
    "            d_model: int = 512,\n",
    "\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.tabular_cat_features_embeddings_table = torch.nn.ModuleList(\n",
    "            [torch.nn.Embedding(num_embeddings=tabular_cat_features_possible_nums[cat_feature_i],\n",
    "                                embedding_dim=tabular_cat_features_embeddings_dim)\n",
    "             for cat_feature_i in range(tabular_cat_features_size)]\n",
    "        )\n",
    "\n",
    "        self.tabular_cat_features_pos_embeddings_table = nn.Embedding(num_embeddings=tabular_cat_features_size + 1,\n",
    "                                                                      embedding_dim=tabular_cat_features_embeddings_dim)\n",
    "\n",
    "        self.tabular_num_features_ffn = FeedForwardLayer(input_size=tabular_num_features_size,\n",
    "                                                         hidden_size=tabular_num_features_ffn_hidden_size,\n",
    "                                                         output_size=tabular_num_features_ffn_output_dim)\n",
    "\n",
    "        self.time_series_cat_features_embeddings_table = nn.ModuleList(\n",
    "            [nn.Embedding(num_embeddings=time_series_cat_features_possible_nums[cat_feature_i],\n",
    "                          embedding_dim=time_series_cat_features_embeddings_dim)\n",
    "             for cat_feature_i in range(time_series_cat_features_size)]\n",
    "        )\n",
    "\n",
    "        self.tabular_cat_features_size = tabular_cat_features_size\n",
    "        self.tabular_num_features_size = tabular_num_features_size\n",
    "        self.tabular_features_size = tabular_cat_features_size + tabular_num_features_size\n",
    "\n",
    "        self.time_series_cat_features_size = time_series_cat_features_size\n",
    "        self.time_series_size = time_series_size\n",
    "\n",
    "        self.column_embedding_table = torch.nn.Embedding(num_embeddings=self.tabular_features_size + 1,\n",
    "                                                         embedding_dim=tabular_cat_features_embeddings_dim)\n",
    "        self.positional_embedding_table = torch.nn.Embedding(num_embeddings=self.time_series_size + 1,\n",
    "                                                             embedding_dim=tabular_cat_features_embeddings_dim)\n",
    "\n",
    "        self.linear_layer = nn.Linear(\n",
    "            in_features=self.time_series_size * tabular_num_features_ffn_output_dim + self.tabular_cat_features_size * tabular_cat_features_embeddings_dim + tabular_num_features_size * tabular_num_features_ffn_output_dim,\n",
    "            out_features=d_model\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            tabular_cat_features: Tensor,\n",
    "            tabular_num_features: Tensor,\n",
    "            time_series_cat_features: Tensor,\n",
    "            time_series_num_features: Tensor\n",
    "    ):\n",
    "        batch_size = tabular_cat_features.shape[0]\n",
    "\n",
    "        tabular_cat_features_embeddings = torch.stack(\n",
    "            [self.tabular_cat_features_embeddings_table[cat_feature_i](tabular_cat_features[:, cat_feature_i].long())\n",
    "             for cat_feature_i in range(tabular_cat_features.shape[1])], dim=0)\n",
    "\n",
    "        tabular_num_features = tabular_num_features.reshape(self.tabular_num_features_size, batch_size, -1)\n",
    "        tabular_num_features_embeddings = self.tabular_num_features_ffn(tabular_num_features)\n",
    "\n",
    "        time_series_cat_features = time_series_cat_features.reshape(self.time_series_size, batch_size, -1)\n",
    "        time_series_cat_features_embeddings = torch.cat([self.time_series_cat_features_embeddings_table[cat_feature_i](\n",
    "            time_series_cat_features[:, :, cat_feature_i].long())\n",
    "            for cat_feature_i in\n",
    "            range(time_series_cat_features.shape[-1])], dim=-1)\n",
    "\n",
    "        time_series_num_features = time_series_num_features.reshape(self.time_series_size, batch_size, -1)\n",
    "\n",
    "        tabular_embeddings = torch.cat([tabular_cat_features_embeddings, tabular_num_features_embeddings], dim=0)\n",
    "        time_series_embeddings = torch.cat([time_series_cat_features_embeddings, time_series_num_features], dim=-1)\n",
    "        \n",
    "        time_series_embeddings += self.column_embedding_table(torch.IntTensor([0]))\n",
    "        for step_i in range(len(time_series_embeddings)):\n",
    "            time_series_embeddings[step_i] += self.positional_embedding_table(torch.IntTensor([step_i + 1]))\n",
    "\n",
    "        tabular_embeddings += self.positional_embedding_table(torch.IntTensor([0]))\n",
    "        for column_i in range(len(tabular_embeddings)):\n",
    "            tabular_embeddings[column_i] += self.column_embedding_table(torch.IntTensor([column_i + 1]))\n",
    "\n",
    "        time_series_embeddings = time_series_embeddings.reshape(batch_size, self.time_series_size, -1)\n",
    "        tabular_embeddings = tabular_embeddings.reshape(batch_size, self.tabular_features_size, -1)\n",
    "\n",
    "        return self.linear_layer(torch.cat([tabular_embeddings, time_series_embeddings], dim=1).reshape(batch_size, -1))\n",
    "\n",
    "\n",
    "class TimeSeriesTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    This class implements a transformer model that can be used for times series\n",
    "    forecasting. This time series transformer model is based on the paper by\n",
    "    Wu et al (2020) [1]. The paper will be referred to as \"the paper\".\n",
    "\n",
    "    A detailed description of the code can be found in my article here:\n",
    "\n",
    "    https://towardsdatascience.com/how-to-make-a-pytorch-transformer-for-time-series-forecasting-69e073d4061e\n",
    "\n",
    "    In cases where the paper does not specify what value was used for a specific\n",
    "    configuration/hyperparameter, this class uses the values from Vaswani et al\n",
    "    (2017) [2] or from PyTorch source code.\n",
    "\n",
    "    Unlike the paper, this class assumes that input layers, positional encoding\n",
    "    layers and linear mapping layers are separate from the encoder and decoder,\n",
    "    i.e. the encoder and decoder only do what is depicted as their sub-layers\n",
    "    in the paper. For practical purposes, this assumption does not make a\n",
    "    difference - it merely means that the linear and positional encoding layers\n",
    "    are implemented inside the present class and not inside the\n",
    "    Encoder() and Decoder() classes.\n",
    "\n",
    "    [1] Wu, N., Green, B., Ben, X., O'banion, S. (2020).\n",
    "    'Deep Transformer Models for Time Series Forecasting:\n",
    "    The Influenza Prevalence Case'.\n",
    "    arXiv:2001.08317 [cs, stat] [Preprint].\n",
    "    Available at: http://arxiv.org/abs/2001.08317 (Accessed: 9 March 2022).\n",
    "\n",
    "    [2] Vaswani, A. et al. (2017)\n",
    "    'Attention Is All You Need'.\n",
    "    arXiv:1706.03762 [cs] [Preprint].\n",
    "    Available at: http://arxiv.org/abs/1706.03762 (Accessed: 9 March 2022).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 tabular_cat_features_size: int,  # 2\n",
    "                 tabular_cat_features_possible_nums: IntTensor,  # [45, 81]\n",
    "                 tabular_cat_features_embeddings_dim: int,  # 32\n",
    "\n",
    "                 tabular_num_features_size: int,  # 1\n",
    "                 tabular_num_features_ffn_hidden_size: int,  # 32\n",
    "                 tabular_num_features_ffn_output_dim: int,  # 22\n",
    "\n",
    "                 time_series_cat_features_size: int,  # 1\n",
    "                 time_series_cat_features_possible_nums: IntTensor,  # [2]\n",
    "                 time_series_cat_features_embeddings_dim: int,  # 16\n",
    "\n",
    "                 enc_seq_len: int,  # 10\n",
    "\n",
    "                 dec_seq_len: int = 4,\n",
    "                 batch_first: bool = True,\n",
    "                 out_seq_len: int = 3,\n",
    "                 dim_val: int = 512,\n",
    "                 n_encoder_layers: int = 4,\n",
    "                 n_decoder_layers: int = 4,\n",
    "                 n_heads: int = 8,\n",
    "                 dropout_encoder: float = 0.2,\n",
    "                 dropout_decoder: float = 0.2,\n",
    "                 dropout_pos_enc: float = 0.1,\n",
    "                 dim_feedforward_encoder: int = 2048,\n",
    "                 dim_feedforward_decoder: int = 2048,\n",
    "                 num_predicted_features: int = 1\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "\n",
    "            input_size: int, number of input variables. 1 if univariate.\n",
    "\n",
    "            dec_seq_len: int, the length of the input sequence fed to the decoder\n",
    "\n",
    "            dim_val: int, aka d_model. All sub-layers in the model produce\n",
    "                     outputs of dimension dim_val\n",
    "\n",
    "            n_encoder_layers: int, number of stacked encoder layers in the encoder\n",
    "\n",
    "            n_decoder_layers: int, number of stacked encoder layers in the decoder\n",
    "\n",
    "            n_heads: int, the number of attention heads (aka parallel attention layers)\n",
    "\n",
    "            dropout_encoder: float, the dropout rate of the encoder\n",
    "\n",
    "            dropout_decoder: float, the dropout rate of the decoder\n",
    "\n",
    "            dropout_pos_enc: float, the dropout rate of the positional encoder\n",
    "\n",
    "            dim_feedforward_encoder: int, number of neurons in the linear layer\n",
    "                                     of the encoder\n",
    "\n",
    "            dim_feedforward_decoder: int, number of neurons in the linear layer\n",
    "                                     of the decoder\n",
    "\n",
    "            num_predicted_features: int, the number of features you want to predict.\n",
    "                                    Most of the time, this will be 1 because we're\n",
    "                                    only forecasting FCR-N prices in DK2, but in\n",
    "                                    we wanted to also predict FCR-D with the same\n",
    "                                    model, num_predicted_features should be 2.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.dec_seq_len = dec_seq_len\n",
    "\n",
    "        # print(\"input_size is: {}\".format(input_size))\n",
    "        # print(\"dim_val is: {}\".format(dim_val))\n",
    "\n",
    "        # Creating the three linear layers needed for the model\n",
    "        self.encoder_embedding_layer = EmbeddingLayer(\n",
    "            tabular_cat_features_size=tabular_cat_features_size,\n",
    "            tabular_cat_features_possible_nums=tabular_cat_features_possible_nums,\n",
    "            tabular_cat_features_embeddings_dim=tabular_cat_features_embeddings_dim,\n",
    "            tabular_num_features_size=tabular_num_features_size,\n",
    "            tabular_num_features_ffn_hidden_size=tabular_num_features_ffn_hidden_size,\n",
    "            tabular_num_features_ffn_output_dim=tabular_num_features_ffn_output_dim,\n",
    "            time_series_cat_features_size=time_series_cat_features_size,\n",
    "            time_series_cat_features_possible_nums=time_series_cat_features_possible_nums,\n",
    "            time_series_cat_features_embeddings_dim=time_series_cat_features_embeddings_dim,\n",
    "            time_series_size=enc_seq_len\n",
    "        )\n",
    "\n",
    "        self.decoder_embedding_layer = EmbeddingLayer(\n",
    "            tabular_cat_features_size=tabular_cat_features_size,\n",
    "            tabular_cat_features_possible_nums=tabular_cat_features_possible_nums,\n",
    "            tabular_cat_features_embeddings_dim=tabular_cat_features_embeddings_dim,\n",
    "            tabular_num_features_size=tabular_num_features_size,\n",
    "            tabular_num_features_ffn_hidden_size=tabular_num_features_ffn_hidden_size,\n",
    "            tabular_num_features_ffn_output_dim=tabular_num_features_ffn_output_dim,\n",
    "            time_series_cat_features_size=time_series_cat_features_size,\n",
    "            time_series_cat_features_possible_nums=time_series_cat_features_possible_nums,\n",
    "            time_series_cat_features_embeddings_dim=time_series_cat_features_embeddings_dim,\n",
    "            time_series_size=dec_seq_len\n",
    "        )\n",
    "\n",
    "        self.linear_mapping = nn.Linear(\n",
    "            in_features=dim_val,\n",
    "            out_features=num_predicted_features\n",
    "        )\n",
    "\n",
    "        # The encoder layer used in the paper is identical to the one used by\n",
    "        # Vaswani et al (2017) on which the PyTorch module is based.\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=dim_val,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=dim_feedforward_encoder,\n",
    "            dropout=dropout_encoder,\n",
    "            batch_first=batch_first\n",
    "        )\n",
    "\n",
    "        # Stack the encoder layers in nn.TransformerDecoder\n",
    "        # It seems the option of passing a normalization instance is redundant\n",
    "        # in my case, because nn.TransformerEncoderLayer per default normalizes\n",
    "        # after each sub-layer\n",
    "        # (https://github.com/pytorch/pytorch/issues/24930).\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            encoder_layer=encoder_layer,\n",
    "            num_layers=n_encoder_layers,\n",
    "            norm=None\n",
    "        )\n",
    "\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=dim_val,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=dim_feedforward_decoder,\n",
    "            dropout=dropout_decoder,\n",
    "            batch_first=batch_first\n",
    "        )\n",
    "\n",
    "        # Stack the decoder layers in nn.TransformerDecoder\n",
    "        # It seems the option of passing a normalization instance is redundant\n",
    "        # in my case, because nn.TransformerDecoderLayer per default normalizes\n",
    "        # after each sub-layer\n",
    "        # (https://github.com/pytorch/pytorch/issues/24930).\n",
    "        self.decoder = nn.TransformerDecoder(\n",
    "            decoder_layer=decoder_layer,\n",
    "            num_layers=n_decoder_layers,\n",
    "            norm=None\n",
    "        )\n",
    "\n",
    "    def forward(self,\n",
    "                tabular_categorical_features,\n",
    "                tabular_numerical_features,\n",
    "                src_time_series_categorical_features,\n",
    "                src_time_series_numerical_features,\n",
    "                trg_time_series_categorical_features,\n",
    "                trg_time_series_numerical_features,\n",
    "                src_mask: Tensor = None,\n",
    "                tgt_mask: Tensor = None) -> Tensor:\n",
    "        \"\"\"\n",
    "        Returns a tensor of shape:\n",
    "\n",
    "        [target_sequence_length, batch_size, num_predicted_features]\n",
    "\n",
    "        Args:\n",
    "\n",
    "            src: the encoder's output sequence. Shape: (S,E) for unbatched input,\n",
    "                 (S, N, E) if batch_first=False or (N, S, E) if\n",
    "                 batch_first=True, where S is the source sequence length,\n",
    "                 N is the batch size, and E is the number of features (1 if univariate)\n",
    "\n",
    "            tgt: the sequence to the decoder. Shape: (T,E) for unbatched input,\n",
    "                 (T, N, E)(T,N,E) if batch_first=False or (N, T, E) if\n",
    "                 batch_first=True, where T is the target sequence length,\n",
    "                 N is the batch size, and E is the number of features (1 if univariate)\n",
    "\n",
    "            src_mask: the mask for the src sequence to prevent the model from\n",
    "                      using data points from the target sequence\n",
    "\n",
    "            tgt_mask: the mask for the tgt sequence to prevent the model from\n",
    "                      using data points from the target sequence\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # print(\"From model.forward(): Size of src as given to forward(): {}\".format(src.size()))\n",
    "        # print(\"From model.forward(): tgt size = {}\".format(tgt.size()))\n",
    "\n",
    "        # Pass throguh the input layer right before the encoder\n",
    "        src = self.encoder_embedding_layer(\n",
    "            tabular_cat_features=tabular_categorical_features,\n",
    "            tabular_num_features=tabular_numerical_features,\n",
    "            time_series_cat_features=src_time_series_categorical_features,\n",
    "            time_series_num_features=src_time_series_numerical_features\n",
    "        )  # src shape: [batch_size, src length, dim_val] regardless of number of input features\n",
    "        # print(\"From model.forward(): Size of src after input layer: {}\".format(src.size()))\n",
    "\n",
    "        # Pass through all the stacked encoder layers in the encoder\n",
    "        # Masking is only needed in the encoder if input sequences are padded\n",
    "        # which they are not in this time series use case, because all my\n",
    "        # input sequences are naturally of the same length.\n",
    "        # (https://github.com/huggingface/transformers/issues/4083)\n",
    "        src = self.encoder(  # src shape: [batch_size, enc_seq_len, dim_val]\n",
    "            src=src\n",
    "        )\n",
    "        # print(\"From model.forward(): Size of src after encoder: {}\".format(src.size()))\n",
    "\n",
    "        # Pass decoder input through decoder input layer\n",
    "        decoder_output = self.decoder_embedding_layer(\n",
    "            tabular_cat_features=tabular_categorical_features,\n",
    "            tabular_num_features=tabular_numerical_features,\n",
    "            time_series_cat_features=trg_time_series_categorical_features,\n",
    "            time_series_num_features=trg_time_series_numerical_features\n",
    "        )  # src shape: [target sequence length, batch_size, dim_val] regardless of number of input features\n",
    "        # print(\"From model.forward(): Size of decoder_output after linear decoder layer: {}\".format(decoder_output.size()))\n",
    "\n",
    "        # if src_mask is not None:\n",
    "        # print(\"From model.forward(): Size of src_mask: {}\".format(src_mask.size()))\n",
    "        # if tgt_mask is not None:\n",
    "        # print(\"From model.forward(): Size of tgt_mask: {}\".format(tgt_mask.size()))\n",
    "\n",
    "        # Pass throguh decoder - output shape: [batch_size, target seq len, dim_val]\n",
    "        decoder_output = self.decoder(\n",
    "            tgt=decoder_output,\n",
    "            memory=src,\n",
    "            tgt_mask=tgt_mask,\n",
    "            memory_mask=src_mask\n",
    "        )\n",
    "\n",
    "        # print(\"From model.forward(): decoder_output shape after decoder: {}\".format(decoder_output.shape))\n",
    "\n",
    "        # Pass through linear mapping\n",
    "        decoder_output = self.linear_mapping(decoder_output)  # shape [batch_size, target seq len]\n",
    "        # print(\"From model.forward(): decoder_output size after linear_mapping = {}\".format(decoder_output.size()))\n",
    "\n",
    "        return decoder_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1587,
   "id": "accd414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1588,
   "id": "d05a1000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tabular_categorical_features.shape = torch.Size([256, 2])\n",
      "tabular_numerical_features.shape = torch.Size([256, 1])\n",
      "src_time_series_categorical_features.shape = torch.Size([256, 10])\n",
      "src_time_series_numerical_features.shape = torch.Size([256, 10, 6])\n",
      "trg_time_series_categorical_features.shape = torch.Size([256, 4])\n",
      "trg_time_series_numerical_features.shape = torch.Size([256, 4, 6])\n",
      "trg_y.shape = torch.Size([256, 1])\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(train_dataloader):\n",
    "    print(f\"tabular_categorical_features.shape = {data['tabular_categorical_features'].shape}\")\n",
    "    print(f\"tabular_numerical_features.shape = {data['tabular_numerical_features'].shape}\")\n",
    "    print(f\"src_time_series_categorical_features.shape = {data['src_time_series_categorical_features'].shape}\")\n",
    "    print(f\"src_time_series_numerical_features.shape = {data['src_time_series_numerical_features'].shape}\")\n",
    "    print(f\"trg_time_series_categorical_features.shape = {data['trg_time_series_categorical_features'].shape}\")\n",
    "    print(f\"trg_time_series_numerical_features.shape = {data['trg_time_series_numerical_features'].shape}\")\n",
    "    print(f\"trg_y.shape = {data['trg_y'].shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1589,
   "id": "5bc6e766",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TimeSeriesTransformer(\n",
    "    tabular_cat_features_size=2,\n",
    "    tabular_cat_features_possible_nums=IntTensor([45, 81]),\n",
    "    tabular_cat_features_embeddings_dim=32,\n",
    "    tabular_num_features_size=1,\n",
    "    tabular_num_features_ffn_hidden_size=32,\n",
    "    tabular_num_features_ffn_output_dim=32,\n",
    "    time_series_cat_features_size=1,\n",
    "    time_series_cat_features_possible_nums=IntTensor([2]),\n",
    "    time_series_cat_features_embeddings_dim=26,\n",
    "\n",
    "    enc_seq_len=10,  # 10\n",
    "\n",
    "    dec_seq_len = 4,\n",
    "    batch_first = True,\n",
    "    out_seq_len = 3,\n",
    "    dim_val = 512,\n",
    "    n_encoder_layers = 4,\n",
    "    n_decoder_layers = 4,\n",
    "    n_heads = 8,\n",
    "    dropout_encoder = 0.2,\n",
    "    dropout_decoder = 0.2,\n",
    "    dropout_pos_enc = 0.1,\n",
    "    dim_feedforward_encoder = 2048,\n",
    "    dim_feedforward_decoder = 2048,\n",
    "    num_predicted_features = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1590,
   "id": "8a442366",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(\n",
    "                tabular_categorical_features=data['tabular_categorical_features'],\n",
    "                tabular_numerical_features=data['tabular_numerical_features'],\n",
    "                src_time_series_categorical_features=data['src_time_series_categorical_features'],\n",
    "                src_time_series_numerical_features=data['src_time_series_numerical_features'],\n",
    "                trg_time_series_categorical_features=data['trg_time_series_categorical_features'],\n",
    "                trg_time_series_numerical_features=data['trg_time_series_numerical_features'],\n",
    "                src_mask = None,\n",
    "                tgt_mask = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1592,
   "id": "745b30a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 1])"
      ]
     },
     "execution_count": 1592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1593,
   "id": "b98fe658",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.HuberLoss(reduction=\"sum\")\n",
    "lr = 0.001  # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "def train(model: nn.Module, epoch: int) -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.\n",
    "    log_interval = 200\n",
    "    start_time = time.time()\n",
    "\n",
    "    num_batches = len(train_dataset) // batch_size\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        output = model(\n",
    "            tabular_categorical_features=data['tabular_categorical_features'],\n",
    "            tabular_numerical_features=data['tabular_numerical_features'],\n",
    "            src_time_series_categorical_features=data['src_time_series_categorical_features'],\n",
    "            src_time_series_numerical_features=data['src_time_series_numerical_features'],\n",
    "            trg_time_series_categorical_features=data['trg_time_series_categorical_features'],\n",
    "            trg_time_series_numerical_features=data['trg_time_series_numerical_features'],\n",
    "            src_mask = None,\n",
    "            tgt_mask = None\n",
    "        )\n",
    "        \n",
    "        loss = criterion(output, data['trg_y'])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if i % log_interval == 0 and i > 0:\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            ppl = math.exp(cur_loss)\n",
    "            print(f'| epoch {epoch:3d} | {i:5d}/{num_batches:5d} batches | '\n",
    "                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
    "                  f'loss {cur_loss} | ppl {ppl:8.2f}')\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(model: nn.Module, eval_dataloader) -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(eval_dataloader):\n",
    "    \n",
    "            output = model(\n",
    "                tabular_categorical_features=data['tabular_categorical_features'],\n",
    "                tabular_numerical_features=data['tabular_numerical_features'],\n",
    "                src_time_series_categorical_features=data['src_time_series_categorical_features'],\n",
    "                src_time_series_numerical_features=data['src_time_series_numerical_features'],\n",
    "                trg_time_series_categorical_features=data['trg_time_series_categorical_features'],\n",
    "                trg_time_series_numerical_features=data['trg_time_series_numerical_features'],\n",
    "                src_mask = None,\n",
    "                tgt_mask = None\n",
    "            )\n",
    "\n",
    "            total_loss += criterion(output, data['trg_y']).item()\n",
    "    return total_loss / (len(val_dataloader) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1595,
   "id": "a843a2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL LOSS: 445.04136959123025\n",
      "TEST LOSS: 7.590121987425251\n",
      "| epoch   0 |   200/  979 batches | lr 0.00 | ms/batch 189.75 | loss 105.6427173948288 | ppl 7586635481788383207010709013582900082094637056.00\n",
      "| epoch   0 |   400/  979 batches | lr 0.00 | ms/batch 188.59 | loss 14.795500617027283 | ppl 2664429.75\n",
      "| epoch   0 |   600/  979 batches | lr 0.00 | ms/batch 187.84 | loss 14.16089455127716 | ppl 1412532.22\n",
      "| epoch   0 |   800/  979 batches | lr 0.00 | ms/batch 187.28 | loss 13.704394474029542 | ppl 894834.87\n",
      "VAL LOSS: 11.01419613832309\n",
      "TEST LOSS: 0.17506870811368214\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1595], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTEST LOSS: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevaluate(model,\u001b[38;5;250m \u001b[39mtest_dataloader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVAL LOSS: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevaluate(model,\u001b[38;5;250m \u001b[39mval_dataloader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTEST LOSS: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevaluate(model,\u001b[38;5;250m \u001b[39mtest_dataloader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1593], line 28\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, epoch)\u001b[0m\n\u001b[1;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     27\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 28\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     31\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/transformer_time_series_forecast/lib/python3.8/site-packages/torch/nn/utils/clip_grad.py:55\u001b[0m, in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ((device, _), ([grads], _)) \u001b[38;5;129;01min\u001b[39;00m grouped_grads\u001b[38;5;241m.\u001b[39mitems():  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (foreach \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m foreach) \u001b[38;5;129;01mand\u001b[39;00m _has_foreach_support(grads, device\u001b[38;5;241m=\u001b[39mdevice):\n\u001b[0;32m---> 55\u001b[0m         norms\u001b[38;5;241m.\u001b[39mextend(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m foreach:\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeach=True was passed, but can\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt use the foreach API on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tensors\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(f\"VAL LOSS: {evaluate(model, val_dataloader)}\")\n",
    "print(f\"TEST LOSS: {evaluate(model, test_dataloader)}\")\n",
    "for i in range(0, 300):\n",
    "    train(model, i)\n",
    "    print(f\"VAL LOSS: {evaluate(model, val_dataloader)}\")\n",
    "    print(f\"TEST LOSS: {evaluate(model, test_dataloader)}\")\n",
    "    torch.save(model.state_dict(), f\"../models/model_epoch_{i+1}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1596,
   "id": "29fc5592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19080949123994803"
      ]
     },
     "execution_count": 1596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1488,
   "id": "be16307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.HuberLoss(reduction=\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1490,
   "id": "057c1997",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1525,
   "id": "ed57a575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 10, 6])"
      ]
     },
     "execution_count": 1525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['src_time_series_numerical_features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1550,
   "id": "972414ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_time_series = data['src_time_series_numerical_features'][:, :, 0]\n",
    "trg_time_series = data['trg_time_series_numerical_features'][:, :, 0]\n",
    "trg_y = data['trg_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1551,
   "id": "e3c1c8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 1551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_time_series[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1559,
   "id": "4ad01c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/astonuser/anaconda3/envs/transformer_time_series_forecast/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but QuantileTransformer was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/astonuser/anaconda3/envs/transformer_time_series_forecast/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but QuantileTransformer was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/astonuser/anaconda3/envs/transformer_time_series_forecast/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but QuantileTransformer was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "original_src_time_series = weekly_sales_quantile_transformer.inverse_transform(src_time_series[0].reshape(-1, 1))\n",
    "original_trg_time_series = weekly_sales_quantile_transformer.inverse_transform(trg_time_series[0].reshape(-1, 1))\n",
    "original_trg_y = weekly_sales_quantile_transformer.inverse_transform(trg_y[0].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1560,
   "id": "3626fb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 1560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_enc_time_series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1562,
   "id": "a891fd40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[57592.1272961]])"
      ]
     },
     "execution_count": 1562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_trg_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1575,
   "id": "244783a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x3549a9c70>]"
      ]
     },
     "execution_count": 1575,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4796e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1507,
   "id": "402d6670",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8573, 0.8568, 0.8569],\n",
      "        [0.8607, 0.8601, 0.8603],\n",
      "        [0.8138, 0.8133, 0.8134],\n",
      "        [0.7793, 0.7789, 0.7790],\n",
      "        [0.7429, 0.7426, 0.7426],\n",
      "        [0.7251, 0.7247, 0.7248],\n",
      "        [0.7289, 0.7285, 0.7286],\n",
      "        [0.7263, 0.7259, 0.7260],\n",
      "        [0.7190, 0.7186, 0.7187],\n",
      "        [0.7200, 0.7196, 0.7197],\n",
      "        [0.7187, 0.7183, 0.7184],\n",
      "        [0.7143, 0.7139, 0.7140],\n",
      "        [0.7089, 0.7085, 0.7086],\n",
      "        [0.7139, 0.7135, 0.7136],\n",
      "        [0.9162, 0.9156, 0.9157],\n",
      "        [0.9102, 0.9096, 0.9098],\n",
      "        [0.9086, 0.9080, 0.9081],\n",
      "        [0.9071, 0.9065, 0.9066],\n",
      "        [0.9088, 0.9082, 0.9083],\n",
      "        [0.9078, 0.9071, 0.9073],\n",
      "        [0.9033, 0.9026, 0.9028],\n",
      "        [0.9030, 0.9024, 0.9025],\n",
      "        [0.9022, 0.9016, 0.9017],\n",
      "        [0.9032, 0.9026, 0.9027],\n",
      "        [0.9023, 0.9016, 0.9018],\n",
      "        [0.9004, 0.8998, 0.8999],\n",
      "        [0.9006, 0.9000, 0.9001],\n",
      "        [0.9016, 0.9009, 0.9011],\n",
      "        [0.5670, 0.5667, 0.5668],\n",
      "        [0.5541, 0.5538, 0.5539],\n",
      "        [0.5587, 0.5584, 0.5585],\n",
      "        [0.5571, 0.5568, 0.5569],\n",
      "        [0.5758, 0.5755, 0.5755],\n",
      "        [0.5890, 0.5887, 0.5887],\n",
      "        [0.5770, 0.5767, 0.5768],\n",
      "        [0.5703, 0.5700, 0.5701],\n",
      "        [0.5432, 0.5429, 0.5430],\n",
      "        [0.5418, 0.5414, 0.5415],\n",
      "        [0.5374, 0.5370, 0.5371],\n",
      "        [0.5250, 0.5246, 0.5247],\n",
      "        [0.5269, 0.5266, 0.5266],\n",
      "        [0.5326, 0.5323, 0.5323],\n",
      "        [0.8838, 0.8833, 0.8834],\n",
      "        [0.8794, 0.8789, 0.8790],\n",
      "        [0.8750, 0.8745, 0.8746],\n",
      "        [0.8736, 0.8730, 0.8731],\n",
      "        [0.8782, 0.8776, 0.8778],\n",
      "        [0.8711, 0.8705, 0.8706],\n",
      "        [0.8637, 0.8631, 0.8632],\n",
      "        [0.8675, 0.8669, 0.8671],\n",
      "        [0.8719, 0.8713, 0.8714],\n",
      "        [0.8755, 0.8749, 0.8751],\n",
      "        [0.8761, 0.8755, 0.8756],\n",
      "        [0.8719, 0.8713, 0.8715],\n",
      "        [0.8715, 0.8709, 0.8711],\n",
      "        [0.8787, 0.8781, 0.8783],\n",
      "        [0.8144, 0.8139, 0.8140],\n",
      "        [0.7814, 0.7810, 0.7811],\n",
      "        [0.7533, 0.7529, 0.7530],\n",
      "        [0.7418, 0.7414, 0.7415],\n",
      "        [0.7337, 0.7333, 0.7334],\n",
      "        [0.7272, 0.7268, 0.7269],\n",
      "        [0.7291, 0.7287, 0.7288],\n",
      "        [0.7343, 0.7338, 0.7339],\n",
      "        [0.6996, 0.6990, 0.6991],\n",
      "        [0.7286, 0.7280, 0.7281],\n",
      "        [0.7338, 0.7332, 0.7333],\n",
      "        [0.7468, 0.7463, 0.7464],\n",
      "        [0.7456, 0.7451, 0.7452],\n",
      "        [0.7327, 0.7322, 0.7323],\n",
      "        [0.3754, 0.3748, 0.3749],\n",
      "        [0.3784, 0.3778, 0.3779],\n",
      "        [0.3610, 0.3604, 0.3605],\n",
      "        [0.3490, 0.3484, 0.3485],\n",
      "        [0.3633, 0.3627, 0.3628],\n",
      "        [0.3489, 0.3482, 0.3484],\n",
      "        [0.3912, 0.3906, 0.3907],\n",
      "        [0.4047, 0.4041, 0.4042],\n",
      "        [0.3720, 0.3715, 0.3716],\n",
      "        [0.3917, 0.3912, 0.3913],\n",
      "        [0.3750, 0.3745, 0.3746],\n",
      "        [0.3789, 0.3784, 0.3785],\n",
      "        [0.3919, 0.3913, 0.3914],\n",
      "        [0.3540, 0.3535, 0.3536],\n",
      "        [0.7434, 0.7428, 0.7429],\n",
      "        [0.7624, 0.7622, 0.7622],\n",
      "        [0.7373, 0.7370, 0.7371],\n",
      "        [0.7338, 0.7335, 0.7336],\n",
      "        [0.7385, 0.7382, 0.7382],\n",
      "        [0.7450, 0.7447, 0.7447],\n",
      "        [0.7371, 0.7370, 0.7370],\n",
      "        [0.7678, 0.7676, 0.7676],\n",
      "        [0.7878, 0.7876, 0.7876],\n",
      "        [0.7971, 0.7969, 0.7969],\n",
      "        [0.7888, 0.7881, 0.7882],\n",
      "        [0.7758, 0.7754, 0.7754],\n",
      "        [0.7664, 0.7660, 0.7660],\n",
      "        [0.7684, 0.7681, 0.7681],\n",
      "        [0.8375, 0.8368, 0.8369],\n",
      "        [0.8624, 0.8615, 0.8617],\n",
      "        [0.8612, 0.8602, 0.8604],\n",
      "        [0.8630, 0.8620, 0.8622],\n",
      "        [0.8676, 0.8667, 0.8669],\n",
      "        [0.8643, 0.8633, 0.8636],\n",
      "        [0.8473, 0.8459, 0.8462],\n",
      "        [0.8500, 0.8487, 0.8490],\n",
      "        [0.8525, 0.8511, 0.8514],\n",
      "        [0.8542, 0.8528, 0.8531],\n",
      "        [0.8363, 0.8350, 0.8353],\n",
      "        [0.8504, 0.8496, 0.8498],\n",
      "        [0.8479, 0.8470, 0.8472],\n",
      "        [0.8525, 0.8517, 0.8519],\n",
      "        [0.8653, 0.8643, 0.8645],\n",
      "        [0.8245, 0.8231, 0.8234],\n",
      "        [0.8165, 0.8156, 0.8158],\n",
      "        [0.8038, 0.8030, 0.8032],\n",
      "        [0.7990, 0.7982, 0.7984],\n",
      "        [0.7903, 0.7895, 0.7897],\n",
      "        [0.8506, 0.8514, 0.8511],\n",
      "        [0.8541, 0.8549, 0.8547],\n",
      "        [0.8665, 0.8673, 0.8670],\n",
      "        [0.8666, 0.8674, 0.8672],\n",
      "        [0.8309, 0.8302, 0.8303],\n",
      "        [0.7826, 0.7813, 0.7816],\n",
      "        [0.7679, 0.7667, 0.7669],\n",
      "        [0.7788, 0.7775, 0.7778],\n",
      "        [0.8216, 0.8201, 0.8204],\n",
      "        [0.8123, 0.8109, 0.8112],\n",
      "        [0.7999, 0.7994, 0.7995],\n",
      "        [0.7866, 0.7861, 0.7863],\n",
      "        [0.7933, 0.7928, 0.7929],\n",
      "        [0.7937, 0.7932, 0.7933],\n",
      "        [0.8011, 0.7998, 0.8001],\n",
      "        [0.8082, 0.8069, 0.8071],\n",
      "        [0.8147, 0.8134, 0.8136],\n",
      "        [0.8173, 0.8159, 0.8162],\n",
      "        [0.8518, 0.8509, 0.8511],\n",
      "        [0.8277, 0.8271, 0.8273],\n",
      "        [0.8243, 0.8236, 0.8238],\n",
      "        [0.8337, 0.8330, 0.8332],\n",
      "        [0.7880, 0.7877, 0.7877],\n",
      "        [0.7440, 0.7431, 0.7432],\n",
      "        [0.7464, 0.7459, 0.7459],\n",
      "        [0.7364, 0.7358, 0.7359],\n",
      "        [0.7551, 0.7545, 0.7546],\n",
      "        [0.7654, 0.7647, 0.7648],\n",
      "        [0.7854, 0.7848, 0.7849],\n",
      "        [0.7955, 0.7948, 0.7950],\n",
      "        [0.8037, 0.8030, 0.8031],\n",
      "        [0.8145, 0.8137, 0.8139],\n",
      "        [0.8215, 0.8207, 0.8209],\n",
      "        [0.8094, 0.8095, 0.8094],\n",
      "        [0.8401, 0.8400, 0.8399],\n",
      "        [0.8383, 0.8383, 0.8382],\n",
      "        [0.6023, 0.6028, 0.6026],\n",
      "        [0.5918, 0.5923, 0.5921],\n",
      "        [0.6009, 0.6013, 0.6011],\n",
      "        [0.6018, 0.6023, 0.6021],\n",
      "        [0.6106, 0.6111, 0.6109],\n",
      "        [0.6101, 0.6105, 0.6103],\n",
      "        [0.5803, 0.5804, 0.5803],\n",
      "        [0.5928, 0.5929, 0.5928],\n",
      "        [0.5959, 0.5959, 0.5959],\n",
      "        [0.5821, 0.5824, 0.5822],\n",
      "        [0.5858, 0.5860, 0.5859],\n",
      "        [0.5672, 0.5675, 0.5673],\n",
      "        [0.5774, 0.5776, 0.5775],\n",
      "        [0.5859, 0.5858, 0.5857],\n",
      "        [0.8523, 0.8513, 0.8514],\n",
      "        [0.8496, 0.8485, 0.8487],\n",
      "        [0.8452, 0.8433, 0.8436],\n",
      "        [0.8453, 0.8445, 0.8446],\n",
      "        [0.8501, 0.8493, 0.8494],\n",
      "        [0.8461, 0.8453, 0.8454],\n",
      "        [0.8407, 0.8399, 0.8400],\n",
      "        [0.8403, 0.8395, 0.8397],\n",
      "        [0.8426, 0.8418, 0.8420],\n",
      "        [0.8469, 0.8461, 0.8463],\n",
      "        [0.8441, 0.8434, 0.8435],\n",
      "        [0.8426, 0.8419, 0.8420],\n",
      "        [0.8429, 0.8422, 0.8423],\n",
      "        [0.8473, 0.8466, 0.8467],\n",
      "        [0.6311, 0.6307, 0.6308],\n",
      "        [0.6364, 0.6360, 0.6361],\n",
      "        [0.6315, 0.6311, 0.6312],\n",
      "        [0.6350, 0.6346, 0.6347],\n",
      "        [0.6439, 0.6435, 0.6436],\n",
      "        [0.6458, 0.6454, 0.6454],\n",
      "        [0.6550, 0.6546, 0.6546],\n",
      "        [0.6457, 0.6454, 0.6454],\n",
      "        [0.6421, 0.6418, 0.6418],\n",
      "        [0.6247, 0.6244, 0.6245],\n",
      "        [0.6429, 0.6418, 0.6420],\n",
      "        [0.6373, 0.6363, 0.6365],\n",
      "        [0.6567, 0.6556, 0.6558],\n",
      "        [0.6829, 0.6818, 0.6820],\n",
      "        [0.8898, 0.8884, 0.8887],\n",
      "        [0.8919, 0.8905, 0.8908],\n",
      "        [0.8810, 0.8795, 0.8799],\n",
      "        [0.8709, 0.8695, 0.8698],\n",
      "        [0.8675, 0.8661, 0.8664],\n",
      "        [0.8544, 0.8530, 0.8533],\n",
      "        [0.8459, 0.8446, 0.8449],\n",
      "        [0.8519, 0.8505, 0.8508],\n",
      "        [0.8570, 0.8557, 0.8560],\n",
      "        [0.8431, 0.8418, 0.8421],\n",
      "        [0.8328, 0.8315, 0.8318],\n",
      "        [0.8308, 0.8295, 0.8298],\n",
      "        [0.8294, 0.8281, 0.8284],\n",
      "        [0.8411, 0.8398, 0.8401],\n",
      "        [0.5270, 0.5260, 0.5262],\n",
      "        [0.5065, 0.5054, 0.5057],\n",
      "        [0.5182, 0.5172, 0.5174],\n",
      "        [0.5142, 0.5132, 0.5134],\n",
      "        [0.5239, 0.5229, 0.5231],\n",
      "        [0.5246, 0.5236, 0.5238],\n",
      "        [0.5333, 0.5323, 0.5325],\n",
      "        [0.5197, 0.5187, 0.5189],\n",
      "        [0.5058, 0.5048, 0.5050],\n",
      "        [0.5176, 0.5165, 0.5168],\n",
      "        [0.4943, 0.4933, 0.4935],\n",
      "        [0.4962, 0.4952, 0.4954],\n",
      "        [0.5096, 0.5086, 0.5088],\n",
      "        [0.5084, 0.5074, 0.5076],\n",
      "        [0.4477, 0.4466, 0.4469],\n",
      "        [0.4459, 0.4448, 0.4450],\n",
      "        [0.3125, 0.3114, 0.3117],\n",
      "        [0.2245, 0.2233, 0.2236],\n",
      "        [0.1248, 0.1234, 0.1237],\n",
      "        [0.0711, 0.0695, 0.0699],\n",
      "        [0.0649, 0.0634, 0.0637],\n",
      "        [0.0643, 0.0627, 0.0630],\n",
      "        [0.2044, 0.2031, 0.2034],\n",
      "        [0.1950, 0.1937, 0.1940],\n",
      "        [0.2033, 0.2020, 0.2023],\n",
      "        [0.1866, 0.1853, 0.1856],\n",
      "        [0.2003, 0.1990, 0.1993],\n",
      "        [0.2265, 0.2253, 0.2256],\n",
      "        [0.2270, 0.2257, 0.2260],\n",
      "        [0.2263, 0.2250, 0.2253],\n",
      "        [0.2333, 0.2321, 0.2323],\n",
      "        [0.2270, 0.2257, 0.2260],\n",
      "        [0.2153, 0.2140, 0.2143],\n",
      "        [0.2197, 0.2185, 0.2188],\n",
      "        [0.2150, 0.2137, 0.2140],\n",
      "        [0.2174, 0.2161, 0.2164],\n",
      "        [0.3899, 0.3889, 0.3891],\n",
      "        [0.3684, 0.3674, 0.3676],\n",
      "        [0.3765, 0.3755, 0.3757],\n",
      "        [0.3833, 0.3822, 0.3825],\n",
      "        [0.3903, 0.3892, 0.3895],\n",
      "        [0.3948, 0.3938, 0.3940],\n",
      "        [0.4080, 0.4070, 0.4072],\n",
      "        [0.4033, 0.4023, 0.4025],\n",
      "        [0.3979, 0.3969, 0.3971],\n",
      "        [0.4056, 0.4046, 0.4048]], grad_fn=<AddmmBackward0>) 0.6766191720962524\n"
     ]
    }
   ],
   "source": [
    "total_loss = 0\n",
    "for i, data in enumerate(val_dataloader):\n",
    "    data['src_time_series_numerical_features']\n",
    "    \n",
    "    output = model(\n",
    "                tabular_categorical_features=data['tabular_categorical_features'],\n",
    "                tabular_numerical_features=data['tabular_numerical_features'],\n",
    "                src_time_series_categorical_features=data['src_time_series_categorical_features'],\n",
    "                src_time_series_numerical_features=data['src_time_series_numerical_features'],\n",
    "                trg_time_series_categorical_features=data['trg_time_series_categorical_features'],\n",
    "                trg_time_series_numerical_features=data['trg_time_series_numerical_features'],\n",
    "                src_mask = None,\n",
    "                tgt_mask = None\n",
    "            )\n",
    "\n",
    "    total_loss += criterion(output, data['trg_y']).item()\n",
    "    \n",
    "    plt.plot()\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1578,
   "id": "bad07021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 1578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1581,
   "id": "550c2463",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/astonuser/anaconda3/envs/transformer_time_series_forecast/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but QuantileTransformer was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "original_output = weekly_sales_quantile_transformer.inverse_transform(output[0].detach().numpy().reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1582,
   "id": "a634c4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35173.832],\n",
       "       [35105.652],\n",
       "       [35122.37 ]], dtype=float32)"
      ]
     },
     "execution_count": 1582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1585,
   "id": "5105c12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x351b9fc70>]"
      ]
     },
     "execution_count": 1585,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(original_src_time_series)\n",
    "plt.plot([9, 10, 11, 12], original_trg_time_series)\n",
    "plt.plot([13], original_trg_y, 'yo')\n",
    "plt.plot([14], original_output[0], 'ro')\n",
    "plt.plot([14], original_output[1], 'ro')\n",
    "plt.plot([14], original_output[2], 'ro')\n",
    "#'ro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeb7b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0328f0f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfb70e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70aa796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ac856b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609f67cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a547e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df48dfb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58268533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f792d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1139,
   "id": "943ac521",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_cat_features_size = 2\n",
    "tabular_features_possible_nums = [45, 81]\n",
    "d_model = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e66ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1243,
   "id": "5e836301",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_cat_embeddings = torch.stack([tabular_features_embeddings[cat_feature_i](data['tabular_categorical_features'][:, cat_feature_i].long())\n",
    "             for cat_feature_i in range(data['tabular_categorical_features'].shape[1])], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1245,
   "id": "e694f5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1])"
      ]
     },
     "execution_count": 1245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tabular_numerical_features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1143,
   "id": "a373c3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tabular_numerical_features'] = data['tabular_numerical_features'].reshape(1, 5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1144,
   "id": "8f8d2e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 1])"
      ]
     },
     "execution_count": 1144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tabular_numerical_features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1146,
   "id": "b81bad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardLayer(torch.nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_size=1,\n",
    "            hidden_size=32,\n",
    "            output_size=32\n",
    "    ):\n",
    "        super(FeedForwardLayer, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1147,
   "id": "2ad8ee2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn = FeedForwardLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1148,
   "id": "60f7a7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_num_features = ffn(data['tabular_numerical_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1149,
   "id": "ce45b7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 32])"
      ]
     },
     "execution_count": 1149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabular_num_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1150,
   "id": "a28dcb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_cat_features_size = 1\n",
    "time_series_cat_features_possible_nums = torch.IntTensor([2])\n",
    "time_series_cat_features_embeddings_dim = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1151,
   "id": "5a43aa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_cat_features_embeddings_table = nn.ModuleList(\n",
    "            [nn.Embedding(num_embeddings=time_series_cat_features_possible_nums[cat_feature_i], embedding_dim=time_series_cat_features_embeddings_dim)\n",
    "             for cat_feature_i in range(time_series_cat_features_size)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1246,
   "id": "40857760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10])"
      ]
     },
     "execution_count": 1246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['src_time_series_categorical_features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1289,
   "id": "49f0ec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['src_time_series_categorical_features'] = data['src_time_series_categorical_features'].reshape(10, 5, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1290,
   "id": "a7958a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = data['src_time_series_categorical_features'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1291,
   "id": "80d0c458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5, 1])"
      ]
     },
     "execution_count": 1291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['src_time_series_categorical_features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1292,
   "id": "59ec2cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_cat_features=torch.cat([time_series_cat_features_embeddings_table[cat_feature_i](data['src_time_series_categorical_features'][:, :, cat_feature_i].long())\n",
    "             for cat_feature_i in range(data['src_time_series_categorical_features'].shape[-1])], dim=-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1293,
   "id": "caa91437",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5, 26])"
      ]
     },
     "execution_count": 1293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series_cat_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1265,
   "id": "9b66e007",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_num_features = data['src_time_series_numerical_features'].reshape(10, 5, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1266,
   "id": "25dbc980",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5, 6])"
      ]
     },
     "execution_count": 1266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series_num_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1267,
   "id": "28b57dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 32])\n",
      "torch.Size([1, 5, 32])\n",
      "torch.Size([10, 5, 26])\n",
      "torch.Size([10, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "print(tabular_cat_embeddings.shape)\n",
    "print(tabular_num_features.shape)\n",
    "print(time_series_cat_features.shape)\n",
    "print(time_series_num_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1268,
   "id": "f43b929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_embeddings = torch.cat([tabular_cat_embeddings, tabular_num_features], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1269,
   "id": "16a7c4fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 32])"
      ]
     },
     "execution_count": 1269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabular_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1273,
   "id": "22e7614d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "print(time_series_num_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1270,
   "id": "d900e35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_embeddings = torch.cat([time_series_cat_features, time_series_num_features], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1271,
   "id": "b1189d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5, 32])"
      ]
     },
     "execution_count": 1271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1215,
   "id": "359f26fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_embedding_table = torch.nn.Embedding(num_embeddings=3 + 1, embedding_dim=32)\n",
    "positional_embedding_table = torch.nn.Embedding(num_embeddings=10 + 1, embedding_dim=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1216,
   "id": "f5ea3cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 32])"
      ]
     },
     "execution_count": 1216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabular_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1217,
   "id": "a856ff58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 32])"
      ]
     },
     "execution_count": 1217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1218,
   "id": "015ad983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4668,  0.3048,  0.2959, -0.3498,  1.1223, -2.4230, -0.3287, -0.1352,\n",
       "         -1.5053,  0.3417,  0.4774,  1.0340,  0.5035, -0.6018,  1.7864, -0.8862,\n",
       "          0.9633,  1.8013, -0.1006,  0.4067,  1.1611,  1.1968, -0.0766,  0.6571,\n",
       "          1.4259,  0.2372, -1.3344, -0.3572,  0.9219,  0.7024, -0.9807,  1.0322]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 1218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_embedding_table(torch.IntTensor([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1219,
   "id": "dd851679",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_embeddings += column_embedding_table(torch.IntTensor([0]))\n",
    "for step_i in range(len(time_series_embeddings)):\n",
    "    time_series_embeddings[step_i] += positional_embedding_table(torch.IntTensor([step_i + 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1220,
   "id": "1aa63997",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_embeddings += positional_embedding_table(torch.IntTensor([0]))\n",
    "for column_i in range(len(tabular_embeddings)):\n",
    "    tabular_embeddings[column_i] += column_embedding_table(torch.IntTensor([column_i + 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a12b88f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1221,
   "id": "adda33c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_embeddings = time_series_embeddings.reshape(5, 10, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1222,
   "id": "8b1abee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 32])"
      ]
     },
     "execution_count": 1222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1223,
   "id": "b5d6b109",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_embeddings = tabular_embeddings.reshape(5, 3, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1224,
   "id": "6feb39f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 32])"
      ]
     },
     "execution_count": 1224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabular_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1249,
   "id": "5408d627",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "catt = torch.cat([tabular_embeddings, time_series_embeddings], dim=1).reshape(batch_size, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1250,
   "id": "b3b023c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 416])"
      ]
     },
     "execution_count": 1250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1555d794",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
